01/07/2021 10:38:08 1
01/07/2021 10:38:08 Launching the MT-DNN training
01/07/2021 10:38:08 Loading data/canonical_data/bert_base_uncased_lower/mnli_train.json as task 0
01/07/2021 10:38:18 Loading data/canonical_data/bert_base_uncased_lower/rte_train.json as task 1
01/07/2021 10:38:18 Loading data/canonical_data/bert_base_uncased_lower/qqp_train.json as task 2
01/07/2021 10:38:24 Loading data/canonical_data/bert_base_uncased_lower/qnli_train.json as task 3
01/07/2021 10:38:28 Loading data/canonical_data/bert_base_uncased_lower/mrpc_train.json as task 4
01/07/2021 10:38:28 Loading data/canonical_data/bert_base_uncased_lower/sst_train.json as task 5
01/07/2021 10:38:29 Loading data/canonical_data/bert_base_uncased_lower/cola_train.json as task 6
01/07/2021 10:38:29 Loading data/canonical_data/bert_base_uncased_lower/stsb_train.json as task 7
01/07/2021 10:38:39 ####################
01/07/2021 10:38:39 {'log_file': 'checkpoints/2021-01-07T2238_full32/log.log', 'tensorboard': False, 'tensorboard_logdir': 'tensorboard_logdir', 'init_checkpoint': 'bert-base-uncased', 'data_dir': 'data/canonical_data/bert_base_uncased_lower', 'data_sort_on': False, 'name': 'farmer', 'task_def': 'experiments/glue/glue_task_def.yml', 'train_datasets': ['mnli', 'rte', 'qqp', 'qnli', 'mrpc', 'sst', 'cola', 'stsb'], 'test_datasets': ['mnli_matched', 'mnli_mismatched', 'rte', 'qqp', 'qnli', 'mrpc', 'sst', 'cola', 'stsb'], 'glue_format_on': False, 'mkd_opt': 0, 'do_padding': False, 'update_bert_opt': 0, 'multi_gpu_on': True, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'max_answer_len': 10, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': 1, 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'encoder_type': <EncoderModelType.BERT: 1>, 'num_hidden_layers': -1, 'bert_model_type': 'bert-base-uncased', 'do_lower_case': False, 'masked_lm_prob': 0.15, 'short_seq_prob': 0.2, 'max_predictions_per_seq': 128, 'bin_on': False, 'bin_size': 64, 'bin_grow_ratio': 0.5, 'cuda': True, 'log_per_updates': 500, 'save_per_updates': 10000, 'save_per_updates_on': False, 'epochs': 5, 'batch_size': 8, 'batch_size_eval': 8, 'optimizer': 'adamax', 'grad_clipping': 0.0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 5e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'adam_eps': 1e-06, 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'model_ckpt': 'checkpoints/model_0.pt', 'resume': False, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'lr_gamma': 0.5, 'scheduler_type': 'ms', 'output_dir': 'checkpoints/2021-01-07T2238_full32', 'seed': 2018, 'grad_accumulation_step': 4, 'fp16': False, 'fp16_opt_level': 'O1', 'adv_train': False, 'adv_opt': 0, 'adv_norm_level': 0, 'adv_p_norm': 'inf', 'adv_alpha': 1, 'adv_k': 1, 'adv_step_size': 0.001, 'adv_noise_var': 1e-05, 'adv_epsilon': 1e-06, 'loss_pred': True, 'collect_uncertainty': None, 'collect_topk': 0.1, 'load_ranked_data': None, 'mc_dropout': 0, 'finetune': False, 'encode_mode': False, 'task_def_list': [{'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7ffadde134c0>', 'n_class': '3', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>,)', 'split_names': "['train', 'matched_dev', 'mismatched_dev', 'matched_test', 'mismatched_test']", 'enable_san': 'False', 'dropout_p': '0.1', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7ffa51080460>', 'n_class': '2', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>,)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.F1: 1>)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7ffa510803d0>', 'n_class': '2', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>,)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.F1: 1>)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseOnly: 1>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>,)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseOnly: 1>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.MCC: 2>)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': '0.05', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '1', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Regression: 2>', 'metric_meta': '(<Metric.Pearson: 3>, <Metric.Spearman: 4>)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.MseCriterion: 1>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.MseCriterion: 1>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}]}
01/07/2021 10:38:39 ####################
01/07/2021 10:38:39 ############# Gradient Accumulation Info #############
01/07/2021 10:38:39 number of step: 595515
01/07/2021 10:38:39 number of grad grad_accumulation step: 4
01/07/2021 10:38:39 adjusted number of step: 148878
01/07/2021 10:38:39 ############# Gradient Accumulation Info #############
01/07/2021 10:38:50 
############# Model Arch of MT-DNN #############
SANBertNetwork(
  (dropout_list): ModuleList(
    (0): DropoutWrapper()
    (1): DropoutWrapper()
    (2): DropoutWrapper()
    (3): DropoutWrapper()
    (4): DropoutWrapper()
    (5): DropoutWrapper()
    (6): DropoutWrapper()
    (7): DropoutWrapper()
  )
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_pred_fc): Linear(in_features=768, out_features=1, bias=True)
  (scoring_list): ModuleList(
    (0): Linear(in_features=768, out_features=3, bias=True)
    (1): Linear(in_features=768, out_features=2, bias=True)
    (2): Linear(in_features=768, out_features=2, bias=True)
    (3): Linear(in_features=768, out_features=2, bias=True)
    (4): Linear(in_features=768, out_features=2, bias=True)
    (5): Linear(in_features=768, out_features=2, bias=True)
    (6): Linear(in_features=768, out_features=2, bias=True)
    (7): Linear(in_features=768, out_features=1, bias=True)
  )
)

01/07/2021 10:38:50 Total number of params: 109495313
01/07/2021 10:38:50 At epoch 0
01/07/2021 10:38:50 Task [ 3] updates[     0] train loss[0.78224] remaining[5:07:36]
01/07/2021 10:41:23 Task [ 0] updates[   500] train loss[0.98079] remaining[2:29:26]
01/07/2021 10:43:53 Task [ 2] updates[  1000] train loss[0.95832] remaining[2:25:31]
01/07/2021 10:46:27 Task [ 2] updates[  1500] train loss[0.93492] remaining[2:23:33]
01/07/2021 10:48:56 Task [ 3] updates[  2000] train loss[0.93467] remaining[2:20:13]
01/07/2021 10:51:25 Task [ 3] updates[  2500] train loss[0.91030] remaining[2:17:22]
01/07/2021 10:53:55 Task [ 5] updates[  3000] train loss[0.88137] remaining[2:14:39]
01/07/2021 10:56:26 Task [ 2] updates[  3500] train loss[0.85628] remaining[2:12:04]
01/07/2021 10:59:00 Task [ 0] updates[  4000] train loss[0.83011] remaining[2:09:54]
01/07/2021 11:01:31 Task [ 3] updates[  4500] train loss[0.80457] remaining[2:07:25]
01/07/2021 11:04:03 Task [ 5] updates[  5000] train loss[0.78145] remaining[2:04:58]
01/07/2021 11:06:35 Task [ 3] updates[  5500] train loss[0.76087] remaining[2:02:28]
01/07/2021 11:09:05 Task [ 2] updates[  6000] train loss[0.74183] remaining[1:59:51]
01/07/2021 11:11:34 Task [ 0] updates[  6500] train loss[0.72438] remaining[1:57:11]
01/07/2021 11:14:04 Task [ 3] updates[  7000] train loss[0.70825] remaining[1:54:39]
01/07/2021 11:16:36 Task [ 0] updates[  7500] train loss[0.69478] remaining[1:52:10]
01/07/2021 11:19:05 Task [ 2] updates[  8000] train loss[0.68212] remaining[1:49:33]
01/07/2021 11:21:36 Task [ 2] updates[  8500] train loss[0.67066] remaining[1:47:03]
01/07/2021 11:24:05 Task [ 0] updates[  9000] train loss[0.65953] remaining[1:44:27]
01/07/2021 11:26:36 Task [ 2] updates[  9500] train loss[0.64922] remaining[1:41:56]
01/07/2021 11:29:07 Task [ 2] updates[ 10000] train loss[0.63967] remaining[1:39:25]
01/07/2021 11:31:37 Task [ 0] updates[ 10500] train loss[0.63121] remaining[1:36:53]
01/07/2021 11:34:08 Task [ 0] updates[ 11000] train loss[0.62355] remaining[1:34:24]
01/07/2021 11:36:39 Task [ 5] updates[ 11500] train loss[0.61582] remaining[1:31:52]
01/07/2021 11:39:10 Task [ 0] updates[ 12000] train loss[0.60838] remaining[1:29:22]
01/07/2021 11:41:40 Task [ 0] updates[ 12500] train loss[0.60178] remaining[1:26:50]
01/07/2021 11:44:03 Task [ 5] updates[ 13000] train loss[0.59540] remaining[1:24:09]
01/07/2021 11:46:34 Task [ 2] updates[ 13500] train loss[0.58937] remaining[1:21:39]
01/07/2021 11:49:07 Task [ 0] updates[ 14000] train loss[0.58377] remaining[1:19:11]
01/07/2021 11:51:39 Task [ 2] updates[ 14500] train loss[0.57845] remaining[1:16:42]
01/07/2021 11:54:12 Task [ 0] updates[ 15000] train loss[0.57330] remaining[1:14:14]
01/07/2021 11:56:43 Task [ 0] updates[ 15500] train loss[0.56815] remaining[1:11:43]
01/07/2021 11:59:15 Task [ 2] updates[ 16000] train loss[0.56272] remaining[1:09:13]
01/08/2021 12:01:47 Task [ 0] updates[ 16500] train loss[0.55843] remaining[1:06:44]
01/08/2021 12:04:16 Task [ 0] updates[ 17000] train loss[0.55421] remaining[1:04:12]
01/08/2021 12:06:46 Task [ 0] updates[ 17500] train loss[0.54973] remaining[1:01:41]
01/08/2021 12:09:20 Task [ 2] updates[ 18000] train loss[0.54588] remaining[0:59:12]
01/08/2021 12:11:50 Task [ 2] updates[ 18500] train loss[0.54206] remaining[0:56:41]
01/08/2021 12:14:24 Task [ 0] updates[ 19000] train loss[0.53816] remaining[0:54:11]
01/08/2021 12:16:54 Task [ 3] updates[ 19500] train loss[0.53442] remaining[0:51:40]
01/08/2021 12:19:27 Task [ 2] updates[ 20000] train loss[0.53106] remaining[0:49:10]
01/08/2021 12:21:59 Task [ 0] updates[ 20500] train loss[0.52752] remaining[0:46:40]
01/08/2021 12:24:30 Task [ 2] updates[ 21000] train loss[0.52445] remaining[0:44:09]
01/08/2021 12:27:01 Task [ 2] updates[ 21500] train loss[0.52116] remaining[0:41:38]
01/08/2021 12:29:32 Task [ 2] updates[ 22000] train loss[0.51798] remaining[0:39:07]
01/08/2021 12:32:03 Task [ 3] updates[ 22500] train loss[0.51525] remaining[0:36:36]
01/08/2021 12:34:35 Task [ 3] updates[ 23000] train loss[0.51243] remaining[0:34:05]
01/08/2021 12:37:11 Task [ 2] updates[ 23500] train loss[0.50960] remaining[0:31:36]
01/08/2021 12:39:43 Task [ 0] updates[ 24000] train loss[0.50700] remaining[0:29:05]
01/08/2021 12:42:15 Task [ 2] updates[ 24500] train loss[0.50431] remaining[0:26:34]
01/08/2021 12:44:42 Task [ 0] updates[ 25000] train loss[0.50179] remaining[0:24:02]
01/08/2021 12:47:13 Task [ 2] updates[ 25500] train loss[0.49933] remaining[0:21:31]
01/08/2021 12:49:41 Task [ 6] updates[ 26000] train loss[0.49680] remaining[0:19:00]
01/08/2021 12:52:14 Task [ 0] updates[ 26500] train loss[0.49461] remaining[0:16:29]
01/08/2021 12:54:46 Task [ 2] updates[ 27000] train loss[0.49245] remaining[0:13:58]
01/08/2021 12:57:15 Task [ 0] updates[ 27500] train loss[0.49035] remaining[0:11:27]
01/08/2021 12:59:41 Task [ 0] updates[ 28000] train loss[0.48826] remaining[0:08:55]
01/08/2021 01:02:09 Task [ 3] updates[ 28500] train loss[0.48615] remaining[0:06:24]
01/08/2021 01:04:40 Task [ 0] updates[ 29000] train loss[0.48388] remaining[0:03:54]
01/08/2021 01:07:13 Task [ 2] updates[ 29500] train loss[0.48184] remaining[0:01:23]
01/08/2021 01:09:04 Task mnli_matched -- epoch 0 -- Dev ACC: 82.374
01/08/2021 01:09:33 [new test scores saved.]
01/08/2021 01:10:02 Task mnli_mismatched -- epoch 0 -- Dev ACC: 82.893
01/08/2021 01:10:31 [new test scores saved.]
01/08/2021 01:10:33 Task rte -- epoch 0 -- Dev ACC: 71.841
01/08/2021 01:10:44 [new test scores saved.]
01/08/2021 01:12:22 Task qqp -- epoch 0 -- Dev ACC: 88.568
01/08/2021 01:12:22 Task qqp -- epoch 0 -- Dev F1: 84.529
01/08/2021 01:28:22 [new test scores saved.]
01/08/2021 01:28:40 Task qnli -- epoch 0 -- Dev ACC: 85.293
01/08/2021 01:29:01 [new test scores saved.]
01/08/2021 01:29:02 Task mrpc -- epoch 0 -- Dev ACC: 76.961
01/08/2021 01:29:02 Task mrpc -- epoch 0 -- Dev F1: 84.641
01/08/2021 01:29:08 [new test scores saved.]
01/08/2021 01:29:09 Task sst -- epoch 0 -- Dev ACC: 91.972
01/08/2021 01:29:13 [new test scores saved.]
01/08/2021 01:29:15 Task cola -- epoch 0 -- Dev ACC: 69.799
01/08/2021 01:29:15 Task cola -- epoch 0 -- Dev MCC: 12.300
01/08/2021 01:29:16 [new test scores saved.]
01/08/2021 01:29:20 Task stsb -- epoch 0 -- Dev Pearson: 86.763
01/08/2021 01:29:20 Task stsb -- epoch 0 -- Dev Spearman: 87.163
01/08/2021 01:29:22 [new test scores saved.]
01/08/2021 01:29:27 At epoch 1
01/08/2021 01:30:35 Task [ 0] updates[ 30000] train loss[0.47991] remaining[2:29:40]
01/08/2021 01:33:05 Task [ 2] updates[ 30500] train loss[0.47794] remaining[2:25:39]
01/08/2021 01:35:37 Task [ 2] updates[ 31000] train loss[0.47626] remaining[2:23:36]
01/08/2021 01:38:06 Task [ 2] updates[ 31500] train loss[0.47432] remaining[2:20:41]
01/08/2021 01:40:34 Task [ 2] updates[ 32000] train loss[0.47265] remaining[2:17:37]
01/08/2021 01:43:04 Task [ 5] updates[ 32500] train loss[0.47098] remaining[2:15:08]
01/08/2021 01:45:33 Task [ 0] updates[ 33000] train loss[0.46935] remaining[2:12:35]
01/08/2021 01:48:05 Task [ 2] updates[ 33500] train loss[0.46764] remaining[2:10:17]
01/08/2021 01:50:36 Task [ 0] updates[ 34000] train loss[0.46611] remaining[2:07:54]
01/08/2021 01:53:08 Task [ 0] updates[ 34500] train loss[0.46446] remaining[2:05:34]
01/08/2021 01:55:41 Task [ 0] updates[ 35000] train loss[0.46279] remaining[2:03:14]
01/08/2021 01:58:12 Task [ 2] updates[ 35500] train loss[0.46122] remaining[2:00:46]
01/08/2021 02:00:43 Task [ 2] updates[ 36000] train loss[0.45951] remaining[1:58:16]
01/08/2021 02:03:14 Task [ 3] updates[ 36500] train loss[0.45775] remaining[1:55:46]
01/08/2021 02:05:47 Task [ 0] updates[ 37000] train loss[0.45617] remaining[1:53:22]
01/08/2021 02:08:17 Task [ 0] updates[ 37500] train loss[0.45474] remaining[1:50:51]
01/08/2021 02:10:49 Task [ 2] updates[ 38000] train loss[0.45317] remaining[1:48:23]
01/08/2021 02:13:19 Task [ 2] updates[ 38500] train loss[0.45168] remaining[1:45:50]
01/08/2021 02:15:48 Task [ 3] updates[ 39000] train loss[0.45011] remaining[1:43:15]
01/08/2021 02:18:18 Task [ 3] updates[ 39500] train loss[0.44858] remaining[1:40:42]
01/08/2021 02:20:48 Task [ 3] updates[ 40000] train loss[0.44702] remaining[1:38:11]
01/08/2021 02:23:18 Task [ 0] updates[ 40500] train loss[0.44548] remaining[1:35:38]
01/08/2021 02:25:47 Task [ 3] updates[ 41000] train loss[0.44398] remaining[1:33:06]
01/08/2021 02:28:20 Task [ 0] updates[ 41500] train loss[0.44241] remaining[1:30:39]
01/08/2021 02:30:52 Task [ 0] updates[ 42000] train loss[0.44080] remaining[1:28:10]
01/08/2021 02:33:23 Task [ 3] updates[ 42500] train loss[0.43923] remaining[1:25:39]
01/08/2021 02:35:53 Task [ 3] updates[ 43000] train loss[0.43775] remaining[1:23:08]
01/08/2021 02:38:24 Task [ 2] updates[ 43500] train loss[0.43616] remaining[1:20:38]
01/08/2021 02:40:55 Task [ 0] updates[ 44000] train loss[0.43461] remaining[1:18:07]
01/08/2021 02:43:26 Task [ 0] updates[ 44500] train loss[0.43300] remaining[1:15:37]
01/08/2021 02:45:57 Task [ 5] updates[ 45000] train loss[0.43151] remaining[1:13:06]
01/08/2021 02:51:23 Task [ 2] updates[ 45500] train loss[0.42992] remaining[1:13:13]
01/08/2021 02:53:51 Task [ 0] updates[ 46000] train loss[0.42846] remaining[1:10:29]
01/08/2021 02:56:19 Task [ 0] updates[ 46500] train loss[0.42715] remaining[1:07:46]
01/08/2021 02:58:46 Task [ 2] updates[ 47000] train loss[0.42565] remaining[1:05:05]
01/08/2021 03:01:16 Task [ 2] updates[ 47500] train loss[0.42429] remaining[1:02:25]
01/08/2021 03:03:44 Task [ 0] updates[ 48000] train loss[0.42287] remaining[0:59:45]
01/08/2021 03:06:10 Task [ 0] updates[ 48500] train loss[0.42157] remaining[0:57:04]
01/08/2021 03:08:36 Task [ 0] updates[ 49000] train loss[0.42009] remaining[0:54:25]
01/08/2021 03:11:04 Task [ 3] updates[ 49500] train loss[0.41878] remaining[0:51:46]
01/08/2021 03:13:31 Task [ 4] updates[ 50000] train loss[0.41744] remaining[0:49:08]
01/08/2021 03:16:03 Task [ 5] updates[ 50500] train loss[0.41625] remaining[0:46:33]
01/08/2021 03:18:29 Task [ 3] updates[ 51000] train loss[0.41499] remaining[0:43:55]
01/08/2021 03:20:59 Task [ 2] updates[ 51500] train loss[0.41367] remaining[0:41:20]
01/08/2021 03:23:27 Task [ 3] updates[ 52000] train loss[0.41245] remaining[0:38:44]
01/08/2021 03:25:55 Task [ 2] updates[ 52500] train loss[0.41131] remaining[0:36:08]
01/08/2021 03:28:23 Task [ 2] updates[ 53000] train loss[0.41010] remaining[0:33:33]
01/08/2021 03:30:51 Task [ 0] updates[ 53500] train loss[0.40890] remaining[0:30:58]
01/08/2021 03:33:21 Task [ 0] updates[ 54000] train loss[0.40775] remaining[0:28:23]
01/08/2021 03:38:50 Task [ 0] updates[ 54500] train loss[0.40657] remaining[0:26:26]
01/08/2021 03:41:21 Task [ 0] updates[ 55000] train loss[0.40543] remaining[0:23:47]
01/08/2021 03:43:48 Task [ 3] updates[ 55500] train loss[0.40431] remaining[0:21:09]
01/08/2021 03:46:15 Task [ 2] updates[ 56000] train loss[0.40309] remaining[0:18:31]
01/08/2021 03:48:42 Task [ 2] updates[ 56500] train loss[0.40210] remaining[0:15:53]
01/08/2021 03:51:09 Task [ 0] updates[ 57000] train loss[0.40110] remaining[0:13:16]
01/08/2021 03:53:36 Task [ 2] updates[ 57500] train loss[0.40007] remaining[0:10:39]
01/08/2021 03:59:09 Task [ 0] updates[ 58000] train loss[0.39894] remaining[0:08:13]
01/08/2021 04:01:40 Task [ 5] updates[ 58500] train loss[0.39789] remaining[0:05:34]
01/08/2021 04:04:09 Task [ 0] updates[ 59000] train loss[0.39676] remaining[0:02:55]
01/08/2021 04:06:41 Task [ 7] updates[ 59500] train loss[0.39574] remaining[0:00:16]
01/08/2021 04:07:27 Task mnli_matched -- epoch 1 -- Dev ACC: 83.933
01/08/2021 04:07:57 [new test scores saved.]
01/08/2021 04:08:28 Task mnli_mismatched -- epoch 1 -- Dev ACC: 84.022
01/08/2021 04:08:58 [new test scores saved.]
01/08/2021 04:08:59 Task rte -- epoch 1 -- Dev ACC: 74.368
01/08/2021 04:09:11 [new test scores saved.]
01/08/2021 04:10:54 Task qqp -- epoch 1 -- Dev ACC: 89.770
01/08/2021 04:10:54 Task qqp -- epoch 1 -- Dev F1: 86.451
01/08/2021 04:27:39 [new test scores saved.]
01/08/2021 04:27:57 Task qnli -- epoch 1 -- Dev ACC: 86.933
01/08/2021 04:28:19 [new test scores saved.]
01/08/2021 04:28:20 Task mrpc -- epoch 1 -- Dev ACC: 76.961
01/08/2021 04:28:20 Task mrpc -- epoch 1 -- Dev F1: 84.740
01/08/2021 04:28:26 [new test scores saved.]
01/08/2021 04:28:28 Task sst -- epoch 1 -- Dev ACC: 92.431
01/08/2021 04:28:32 [new test scores saved.]
01/08/2021 04:28:33 Task cola -- epoch 1 -- Dev ACC: 77.852
01/08/2021 04:28:33 Task cola -- epoch 1 -- Dev MCC: 44.140
01/08/2021 04:28:35 [new test scores saved.]
01/08/2021 04:28:38 Task stsb -- epoch 1 -- Dev Pearson: 87.478
01/08/2021 04:28:38 Task stsb -- epoch 1 -- Dev Spearman: 87.658
01/08/2021 04:28:41 [new test scores saved.]
01/08/2021 04:28:46 At epoch 2
01/08/2021 04:31:02 Task [ 3] updates[ 60000] train loss[0.39472] remaining[2:28:17]
01/08/2021 04:33:32 Task [ 0] updates[ 60500] train loss[0.39380] remaining[2:24:52]
01/08/2021 04:36:06 Task [ 0] updates[ 61000] train loss[0.39280] remaining[2:23:16]
01/08/2021 04:38:38 Task [ 3] updates[ 61500] train loss[0.39178] remaining[2:20:52]
01/08/2021 04:41:09 Task [ 0] updates[ 62000] train loss[0.39091] remaining[2:18:05]
01/08/2021 04:43:38 Task [ 2] updates[ 62500] train loss[0.39002] remaining[2:15:12]
01/08/2021 04:46:07 Task [ 0] updates[ 63000] train loss[0.38914] remaining[2:12:22]
01/08/2021 04:48:38 Task [ 2] updates[ 63500] train loss[0.38824] remaining[2:09:56]
01/08/2021 04:51:09 Task [ 2] updates[ 64000] train loss[0.38738] remaining[2:07:23]
01/08/2021 04:53:39 Task [ 0] updates[ 64500] train loss[0.38643] remaining[2:04:50]
01/08/2021 04:56:10 Task [ 0] updates[ 65000] train loss[0.38549] remaining[2:02:19]
01/08/2021 04:58:40 Task [ 3] updates[ 65500] train loss[0.38460] remaining[1:59:43]
01/08/2021 05:01:08 Task [ 2] updates[ 66000] train loss[0.38366] remaining[1:57:04]
01/08/2021 05:03:39 Task [ 2] updates[ 66500] train loss[0.38275] remaining[1:54:34]
01/08/2021 05:06:08 Task [ 0] updates[ 67000] train loss[0.38190] remaining[1:51:59]
01/08/2021 05:08:37 Task [ 5] updates[ 67500] train loss[0.38102] remaining[1:49:24]
01/08/2021 05:11:05 Task [ 0] updates[ 68000] train loss[0.38014] remaining[1:46:47]
01/08/2021 05:13:30 Task [ 0] updates[ 68500] train loss[0.37928] remaining[1:44:05]
01/08/2021 05:16:00 Task [ 0] updates[ 69000] train loss[0.37840] remaining[1:41:36]
01/08/2021 05:18:29 Task [ 0] updates[ 69500] train loss[0.37752] remaining[1:39:05]
01/08/2021 05:20:57 Task [ 2] updates[ 70000] train loss[0.37661] remaining[1:36:30]
01/08/2021 05:23:26 Task [ 2] updates[ 70500] train loss[0.37570] remaining[1:33:58]
01/08/2021 05:25:53 Task [ 0] updates[ 71000] train loss[0.37479] remaining[1:31:26]
01/08/2021 05:28:22 Task [ 3] updates[ 71500] train loss[0.37387] remaining[1:28:54]
01/08/2021 05:30:50 Task [ 0] updates[ 72000] train loss[0.37292] remaining[1:26:22]
01/08/2021 05:33:17 Task [ 0] updates[ 72500] train loss[0.37203] remaining[1:23:49]
01/08/2021 05:35:45 Task [ 3] updates[ 73000] train loss[0.37107] remaining[1:21:18]
01/08/2021 05:38:13 Task [ 0] updates[ 73500] train loss[0.37014] remaining[1:18:47]
01/08/2021 05:40:41 Task [ 6] updates[ 74000] train loss[0.36919] remaining[1:16:17]
01/08/2021 05:43:11 Task [ 3] updates[ 74500] train loss[0.36823] remaining[1:13:48]
01/08/2021 05:45:39 Task [ 3] updates[ 75000] train loss[0.36730] remaining[1:11:17]
01/08/2021 05:48:09 Task [ 2] updates[ 75500] train loss[0.36627] remaining[1:08:49]
01/08/2021 05:50:39 Task [ 5] updates[ 76000] train loss[0.36543] remaining[1:06:20]
01/08/2021 05:53:08 Task [ 0] updates[ 76500] train loss[0.36454] remaining[1:03:50]
01/08/2021 05:55:36 Task [ 0] updates[ 77000] train loss[0.36361] remaining[1:01:20]
01/08/2021 05:58:06 Task [ 4] updates[ 77500] train loss[0.36276] remaining[0:58:51]
01/08/2021 06:00:35 Task [ 2] updates[ 78000] train loss[0.36192] remaining[0:56:22]
01/08/2021 06:03:05 Task [ 0] updates[ 78500] train loss[0.36103] remaining[0:53:53]
01/08/2021 06:05:34 Task [ 0] updates[ 79000] train loss[0.36015] remaining[0:51:23]
01/08/2021 06:08:04 Task [ 0] updates[ 79500] train loss[0.35938] remaining[0:48:54]
01/08/2021 06:10:33 Task [ 0] updates[ 80000] train loss[0.35849] remaining[0:46:25]
01/08/2021 06:13:01 Task [ 3] updates[ 80500] train loss[0.35769] remaining[0:43:55]
01/08/2021 06:15:30 Task [ 2] updates[ 81000] train loss[0.35683] remaining[0:41:26]
01/08/2021 06:17:57 Task [ 2] updates[ 81500] train loss[0.35600] remaining[0:38:56]
01/08/2021 06:20:26 Task [ 0] updates[ 82000] train loss[0.35521] remaining[0:36:26]
01/08/2021 06:22:53 Task [ 0] updates[ 82500] train loss[0.35445] remaining[0:33:57]
01/08/2021 06:25:21 Task [ 0] updates[ 83000] train loss[0.35366] remaining[0:31:27]
01/08/2021 06:27:50 Task [ 0] updates[ 83500] train loss[0.35289] remaining[0:28:58]
01/08/2021 06:30:20 Task [ 2] updates[ 84000] train loss[0.35208] remaining[0:26:29]
01/08/2021 06:32:49 Task [ 0] updates[ 84500] train loss[0.35127] remaining[0:24:00]
01/08/2021 06:35:17 Task [ 2] updates[ 85000] train loss[0.35049] remaining[0:21:30]
01/08/2021 06:37:47 Task [ 0] updates[ 85500] train loss[0.34967] remaining[0:19:01]
01/08/2021 06:40:17 Task [ 3] updates[ 86000] train loss[0.34889] remaining[0:16:32]
01/08/2021 06:42:45 Task [ 2] updates[ 86500] train loss[0.34818] remaining[0:14:03]
01/08/2021 06:45:12 Task [ 0] updates[ 87000] train loss[0.34745] remaining[0:11:34]
01/08/2021 06:47:40 Task [ 0] updates[ 87500] train loss[0.34672] remaining[0:09:04]
01/08/2021 06:50:09 Task [ 0] updates[ 88000] train loss[0.34597] remaining[0:06:35]
01/08/2021 06:52:34 Task [ 5] updates[ 88500] train loss[0.34523] remaining[0:04:06]
01/08/2021 06:55:00 Task [ 5] updates[ 89000] train loss[0.34454] remaining[0:01:37]
01/08/2021 06:57:06 Task mnli_matched -- epoch 2 -- Dev ACC: 84.177
01/08/2021 06:57:34 [new test scores saved.]
01/08/2021 06:58:03 Task mnli_mismatched -- epoch 2 -- Dev ACC: 84.378
01/08/2021 06:58:32 [new test scores saved.]
01/08/2021 06:58:34 Task rte -- epoch 2 -- Dev ACC: 76.173
01/08/2021 06:58:44 [new test scores saved.]
01/08/2021 07:00:23 Task qqp -- epoch 2 -- Dev ACC: 90.262
01/08/2021 07:00:23 Task qqp -- epoch 2 -- Dev F1: 87.079
01/08/2021 07:16:25 [new test scores saved.]
01/08/2021 07:16:44 Task qnli -- epoch 2 -- Dev ACC: 86.863
01/08/2021 07:17:05 [new test scores saved.]
01/08/2021 07:17:06 Task mrpc -- epoch 2 -- Dev ACC: 79.657
01/08/2021 07:17:06 Task mrpc -- epoch 2 -- Dev F1: 86.097
01/08/2021 07:17:11 [new test scores saved.]
01/08/2021 07:17:13 Task sst -- epoch 2 -- Dev ACC: 92.775
01/08/2021 07:17:17 [new test scores saved.]
01/08/2021 07:17:18 Task cola -- epoch 2 -- Dev ACC: 78.907
01/08/2021 07:17:18 Task cola -- epoch 2 -- Dev MCC: 47.210
01/08/2021 07:17:20 [new test scores saved.]
01/08/2021 07:17:23 Task stsb -- epoch 2 -- Dev Pearson: 87.137
01/08/2021 07:17:23 Task stsb -- epoch 2 -- Dev Spearman: 87.339
01/08/2021 07:17:26 [new test scores saved.]
01/08/2021 07:17:31 At epoch 3
01/08/2021 07:18:22 Task [ 2] updates[ 89500] train loss[0.34381] remaining[2:25:44]
01/08/2021 07:20:51 Task [ 0] updates[ 90000] train loss[0.34309] remaining[2:24:04]
01/08/2021 07:23:19 Task [ 0] updates[ 90500] train loss[0.34244] remaining[2:21:11]
01/08/2021 07:25:47 Task [ 0] updates[ 91000] train loss[0.34171] remaining[2:18:52]
01/08/2021 07:28:15 Task [ 3] updates[ 91500] train loss[0.34104] remaining[2:16:19]
01/08/2021 07:30:42 Task [ 5] updates[ 92000] train loss[0.34039] remaining[2:13:36]
01/08/2021 07:33:10 Task [ 5] updates[ 92500] train loss[0.33977] remaining[2:11:07]
01/08/2021 07:35:39 Task [ 0] updates[ 93000] train loss[0.33912] remaining[2:08:48]
01/08/2021 07:38:07 Task [ 2] updates[ 93500] train loss[0.33849] remaining[2:06:20]
01/08/2021 07:40:36 Task [ 2] updates[ 94000] train loss[0.33786] remaining[2:04:00]
01/08/2021 07:43:05 Task [ 2] updates[ 94500] train loss[0.33719] remaining[2:01:32]
01/08/2021 07:45:31 Task [ 0] updates[ 95000] train loss[0.33655] remaining[1:58:54]
01/08/2021 07:47:59 Task [ 5] updates[ 95500] train loss[0.33586] remaining[1:56:29]
01/08/2021 07:50:26 Task [ 2] updates[ 96000] train loss[0.33517] remaining[1:53:56]
01/08/2021 07:52:54 Task [ 0] updates[ 96500] train loss[0.33448] remaining[1:51:28]
01/08/2021 07:55:25 Task [ 2] updates[ 97000] train loss[0.33389] remaining[1:49:09]
01/08/2021 07:57:56 Task [ 2] updates[ 97500] train loss[0.33323] remaining[1:46:50]
01/08/2021 08:00:25 Task [ 0] updates[ 98000] train loss[0.33258] remaining[1:44:22]
01/08/2021 08:02:51 Task [ 0] updates[ 98500] train loss[0.33194] remaining[1:41:49]
01/08/2021 08:05:19 Task [ 3] updates[ 99000] train loss[0.33128] remaining[1:39:19]
01/08/2021 08:07:47 Task [ 0] updates[ 99500] train loss[0.33059] remaining[1:36:50]
01/08/2021 08:10:14 Task [ 0] updates[100000] train loss[0.32993] remaining[1:34:20]
01/08/2021 08:12:42 Task [ 3] updates[100500] train loss[0.32926] remaining[1:31:52]
01/08/2021 08:15:11 Task [ 3] updates[101000] train loss[0.32860] remaining[1:29:25]
01/08/2021 08:17:39 Task [ 0] updates[101500] train loss[0.32793] remaining[1:26:57]
01/08/2021 08:20:08 Task [ 0] updates[102000] train loss[0.32724] remaining[1:24:29]
01/08/2021 08:22:38 Task [ 0] updates[102500] train loss[0.32658] remaining[1:22:03]
01/08/2021 08:25:08 Task [ 2] updates[103000] train loss[0.32589] remaining[1:19:37]
01/08/2021 08:27:27 Task [ 3] updates[103500] train loss[0.32522] remaining[1:16:58]
01/08/2021 08:29:47 Task [ 0] updates[104000] train loss[0.32452] remaining[1:14:22]
01/08/2021 08:32:13 Task [ 5] updates[104500] train loss[0.32382] remaining[1:11:53]
01/08/2021 08:34:43 Task [ 3] updates[105000] train loss[0.32314] remaining[1:09:27]
01/08/2021 08:37:13 Task [ 5] updates[105500] train loss[0.32244] remaining[1:07:01]
01/08/2021 08:39:43 Task [ 3] updates[106000] train loss[0.32183] remaining[1:04:35]
01/08/2021 08:42:15 Task [ 0] updates[106500] train loss[0.32115] remaining[1:02:10]
01/08/2021 08:44:43 Task [ 2] updates[107000] train loss[0.32051] remaining[0:59:42]
01/08/2021 08:47:11 Task [ 2] updates[107500] train loss[0.31988] remaining[0:57:14]
01/08/2021 08:49:40 Task [ 2] updates[108000] train loss[0.31926] remaining[0:54:47]
01/08/2021 08:52:08 Task [ 2] updates[108500] train loss[0.31859] remaining[0:52:19]
01/08/2021 08:54:36 Task [ 2] updates[109000] train loss[0.31797] remaining[0:49:51]
01/08/2021 08:57:05 Task [ 0] updates[109500] train loss[0.31732] remaining[0:47:23]
01/08/2021 08:59:31 Task [ 5] updates[110000] train loss[0.31671] remaining[0:44:54]
01/08/2021 09:01:57 Task [ 0] updates[110500] train loss[0.31610] remaining[0:42:25]
01/08/2021 09:04:23 Task [ 0] updates[111000] train loss[0.31547] remaining[0:39:57]
01/08/2021 09:06:50 Task [ 5] updates[111500] train loss[0.31485] remaining[0:37:28]
01/08/2021 09:09:15 Task [ 0] updates[112000] train loss[0.31429] remaining[0:35:00]
01/08/2021 09:11:39 Task [ 2] updates[112500] train loss[0.31367] remaining[0:32:31]
01/08/2021 09:14:05 Task [ 2] updates[113000] train loss[0.31307] remaining[0:30:02]
01/08/2021 09:16:33 Task [ 0] updates[113500] train loss[0.31249] remaining[0:27:35]
01/08/2021 09:18:59 Task [ 0] updates[114000] train loss[0.31189] remaining[0:25:07]
01/08/2021 09:21:28 Task [ 0] updates[114500] train loss[0.31130] remaining[0:22:39]
01/08/2021 09:23:54 Task [ 2] updates[115000] train loss[0.31076] remaining[0:20:11]
01/08/2021 09:26:15 Task [ 2] updates[115500] train loss[0.31014] remaining[0:17:43]
01/08/2021 09:28:43 Task [ 3] updates[116000] train loss[0.30961] remaining[0:15:15]
01/08/2021 09:31:11 Task [ 0] updates[116500] train loss[0.30907] remaining[0:12:48]
01/08/2021 09:33:39 Task [ 0] updates[117000] train loss[0.30856] remaining[0:10:20]
01/08/2021 09:36:08 Task [ 0] updates[117500] train loss[0.30799] remaining[0:07:53]
01/08/2021 09:38:35 Task [ 2] updates[118000] train loss[0.30744] remaining[0:05:25]
01/08/2021 09:40:59 Task [ 2] updates[118500] train loss[0.30686] remaining[0:02:57]
01/08/2021 09:43:27 Task [ 0] updates[119000] train loss[0.30630] remaining[0:00:30]
01/08/2021 09:44:25 Task mnli_matched -- epoch 3 -- Dev ACC: 84.167
01/08/2021 09:44:54 [new test scores saved.]
01/08/2021 09:45:23 Task mnli_mismatched -- epoch 3 -- Dev ACC: 84.530
01/08/2021 09:45:52 [new test scores saved.]
01/08/2021 09:45:53 Task rte -- epoch 3 -- Dev ACC: 78.700
01/08/2021 09:46:04 [new test scores saved.]
01/08/2021 09:47:42 Task qqp -- epoch 3 -- Dev ACC: 90.655
01/08/2021 09:47:42 Task qqp -- epoch 3 -- Dev F1: 87.456
01/08/2021 10:03:39 [new test scores saved.]
01/08/2021 10:03:57 Task qnli -- epoch 3 -- Dev ACC: 87.666
01/08/2021 10:04:18 [new test scores saved.]
01/08/2021 10:04:19 Task mrpc -- epoch 3 -- Dev ACC: 79.657
01/08/2021 10:04:19 Task mrpc -- epoch 3 -- Dev F1: 85.908
01/08/2021 10:04:24 [new test scores saved.]
01/08/2021 10:04:26 Task sst -- epoch 3 -- Dev ACC: 93.234
01/08/2021 10:04:30 [new test scores saved.]
01/08/2021 10:04:31 Task cola -- epoch 3 -- Dev ACC: 80.153
01/08/2021 10:04:31 Task cola -- epoch 3 -- Dev MCC: 50.759
01/08/2021 10:04:33 [new test scores saved.]
01/08/2021 10:04:36 Task stsb -- epoch 3 -- Dev Pearson: 86.996
01/08/2021 10:04:36 Task stsb -- epoch 3 -- Dev Spearman: 87.257
01/08/2021 10:04:39 [new test scores saved.]
01/08/2021 10:04:44 At epoch 4
01/08/2021 10:06:36 Task [ 3] updates[119500] train loss[0.30577] remaining[2:19:12]
01/08/2021 10:08:59 Task [ 2] updates[120000] train loss[0.30527] remaining[2:17:00]
01/08/2021 10:11:26 Task [ 0] updates[120500] train loss[0.30475] remaining[2:16:21]
01/08/2021 10:13:54 Task [ 3] updates[121000] train loss[0.30418] remaining[2:14:45]
01/08/2021 10:16:19 Task [ 0] updates[121500] train loss[0.30369] remaining[2:12:17]
01/08/2021 10:18:45 Task [ 2] updates[122000] train loss[0.30321] remaining[2:10:06]
01/08/2021 10:21:11 Task [ 0] updates[122500] train loss[0.30271] remaining[2:07:43]
01/08/2021 10:23:38 Task [ 0] updates[123000] train loss[0.30222] remaining[2:05:36]
01/08/2021 10:26:07 Task [ 5] updates[123500] train loss[0.30173] remaining[2:03:30]
01/08/2021 10:28:33 Task [ 2] updates[124000] train loss[0.30122] remaining[2:00:59]
01/08/2021 10:30:55 Task [ 0] updates[124500] train loss[0.30072] remaining[1:58:20]
01/08/2021 10:33:23 Task [ 2] updates[125000] train loss[0.30024] remaining[1:56:01]
01/08/2021 10:35:50 Task [ 2] updates[125500] train loss[0.29972] remaining[1:53:39]
01/08/2021 10:38:17 Task [ 3] updates[126000] train loss[0.29918] remaining[1:51:19]
01/08/2021 10:40:45 Task [ 2] updates[126500] train loss[0.29871] remaining[1:48:59]
01/08/2021 10:43:13 Task [ 0] updates[127000] train loss[0.29821] remaining[1:46:38]
01/08/2021 10:45:42 Task [ 2] updates[127500] train loss[0.29773] remaining[1:44:18]
01/08/2021 10:48:09 Task [ 0] updates[128000] train loss[0.29723] remaining[1:41:54]
01/08/2021 10:50:37 Task [ 0] updates[128500] train loss[0.29675] remaining[1:39:32]
01/08/2021 10:53:04 Task [ 2] updates[129000] train loss[0.29625] remaining[1:37:06]
01/08/2021 10:55:30 Task [ 0] updates[129500] train loss[0.29575] remaining[1:34:38]
01/08/2021 10:57:55 Task [ 0] updates[130000] train loss[0.29524] remaining[1:32:09]
01/08/2021 11:00:21 Task [ 3] updates[130500] train loss[0.29475] remaining[1:29:42]
01/08/2021 11:02:51 Task [ 0] updates[131000] train loss[0.29425] remaining[1:27:20]
01/08/2021 11:05:21 Task [ 0] updates[131500] train loss[0.29372] remaining[1:24:58]
01/08/2021 11:07:49 Task [ 3] updates[132000] train loss[0.29323] remaining[1:22:34]
01/08/2021 11:10:17 Task [ 2] updates[132500] train loss[0.29270] remaining[1:20:08]
01/08/2021 11:12:43 Task [ 2] updates[133000] train loss[0.29218] remaining[1:17:41]
01/08/2021 11:15:10 Task [ 2] updates[133500] train loss[0.29169] remaining[1:15:15]
01/08/2021 11:17:38 Task [ 2] updates[134000] train loss[0.29117] remaining[1:12:48]
01/08/2021 11:20:06 Task [ 3] updates[134500] train loss[0.29062] remaining[1:10:23]
01/08/2021 11:22:37 Task [ 3] updates[135000] train loss[0.29009] remaining[1:08:00]
01/08/2021 11:25:05 Task [ 5] updates[135500] train loss[0.28962] remaining[1:05:33]
01/08/2021 11:27:33 Task [ 2] updates[136000] train loss[0.28913] remaining[1:03:07]
01/08/2021 11:29:58 Task [ 3] updates[136500] train loss[0.28863] remaining[1:00:39]
01/08/2021 11:32:29 Task [ 0] updates[137000] train loss[0.28813] remaining[0:58:14]
01/08/2021 11:34:58 Task [ 2] updates[137500] train loss[0.28767] remaining[0:55:48]
01/08/2021 11:37:26 Task [ 2] updates[138000] train loss[0.28718] remaining[0:53:22]
01/08/2021 11:39:55 Task [ 2] updates[138500] train loss[0.28670] remaining[0:50:55]
01/08/2021 11:42:23 Task [ 0] updates[139000] train loss[0.28625] remaining[0:48:29]
01/08/2021 11:44:54 Task [ 0] updates[139500] train loss[0.28575] remaining[0:46:03]
01/08/2021 11:47:22 Task [ 2] updates[140000] train loss[0.28529] remaining[0:43:36]
01/08/2021 11:49:52 Task [ 0] updates[140500] train loss[0.28481] remaining[0:41:10]
01/08/2021 11:52:23 Task [ 4] updates[141000] train loss[0.28439] remaining[0:38:44]
01/08/2021 11:54:53 Task [ 5] updates[141500] train loss[0.28392] remaining[0:36:17]
01/08/2021 11:57:23 Task [ 0] updates[142000] train loss[0.28353] remaining[0:33:50]
01/08/2021 11:59:51 Task [ 0] updates[142500] train loss[0.28306] remaining[0:31:23]
01/08/2021 12:02:18 Task [ 0] updates[143000] train loss[0.28261] remaining[0:28:55]
01/08/2021 12:04:48 Task [ 2] updates[143500] train loss[0.28216] remaining[0:26:28]
01/08/2021 12:07:18 Task [ 3] updates[144000] train loss[0.28172] remaining[0:24:01]
01/08/2021 12:09:49 Task [ 2] updates[144500] train loss[0.28130] remaining[0:21:33]
01/08/2021 12:12:20 Task [ 2] updates[145000] train loss[0.28084] remaining[0:19:06]
01/08/2021 12:14:50 Task [ 3] updates[145500] train loss[0.28041] remaining[0:16:39]
01/08/2021 12:17:20 Task [ 3] updates[146000] train loss[0.28000] remaining[0:14:11]
01/08/2021 12:19:50 Task [ 3] updates[146500] train loss[0.27960] remaining[0:11:43]
01/08/2021 12:22:19 Task [ 0] updates[147000] train loss[0.27920] remaining[0:09:15]
01/08/2021 12:24:49 Task [ 0] updates[147500] train loss[0.27878] remaining[0:06:48]
01/08/2021 12:27:18 Task [ 3] updates[148000] train loss[0.27835] remaining[0:04:20]
01/08/2021 12:29:48 Task [ 0] updates[148500] train loss[0.27795] remaining[0:01:52]
01/08/2021 12:32:11 Task mnli_matched -- epoch 4 -- Dev ACC: 84.503
01/08/2021 12:32:41 [new test scores saved.]
01/08/2021 12:33:11 Task mnli_mismatched -- epoch 4 -- Dev ACC: 84.581
01/08/2021 12:33:39 [new test scores saved.]
01/08/2021 12:33:41 Task rte -- epoch 4 -- Dev ACC: 78.339
01/08/2021 12:33:52 [new test scores saved.]
01/08/2021 12:35:31 Task qqp -- epoch 4 -- Dev ACC: 90.702
01/08/2021 12:35:31 Task qqp -- epoch 4 -- Dev F1: 87.534
01/08/2021 12:51:59 [new test scores saved.]
01/08/2021 12:52:17 Task qnli -- epoch 4 -- Dev ACC: 87.805
01/08/2021 12:52:39 [new test scores saved.]
01/08/2021 12:52:40 Task mrpc -- epoch 4 -- Dev ACC: 79.657
01/08/2021 12:52:40 Task mrpc -- epoch 4 -- Dev F1: 85.565
01/08/2021 12:52:46 [new test scores saved.]
01/08/2021 12:52:47 Task sst -- epoch 4 -- Dev ACC: 93.005
01/08/2021 12:52:51 [new test scores saved.]
01/08/2021 12:52:53 Task cola -- epoch 4 -- Dev ACC: 81.304
01/08/2021 12:52:53 Task cola -- epoch 4 -- Dev MCC: 53.772
01/08/2021 12:52:54 [new test scores saved.]
01/08/2021 12:52:58 Task stsb -- epoch 4 -- Dev Pearson: 87.131
01/08/2021 12:52:58 Task stsb -- epoch 4 -- Dev Spearman: 87.277
01/08/2021 12:53:01 [new test scores saved.]
