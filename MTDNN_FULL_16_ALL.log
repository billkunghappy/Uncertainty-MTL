01/07/2021 10:35:58 1
01/07/2021 10:35:58 Launching the MT-DNN training
01/07/2021 10:35:58 Loading data/canonical_data/bert_base_uncased_lower/mnli_train.json as task 0
01/07/2021 10:36:07 Loading data/canonical_data/bert_base_uncased_lower/rte_train.json as task 1
01/07/2021 10:36:07 Loading data/canonical_data/bert_base_uncased_lower/qqp_train.json as task 2
01/07/2021 10:36:13 Loading data/canonical_data/bert_base_uncased_lower/qnli_train.json as task 3
01/07/2021 10:36:17 Loading data/canonical_data/bert_base_uncased_lower/mrpc_train.json as task 4
01/07/2021 10:36:17 Loading data/canonical_data/bert_base_uncased_lower/sst_train.json as task 5
01/07/2021 10:36:17 Loading data/canonical_data/bert_base_uncased_lower/cola_train.json as task 6
01/07/2021 10:36:17 Loading data/canonical_data/bert_base_uncased_lower/stsb_train.json as task 7
01/07/2021 10:36:27 ####################
01/07/2021 10:36:27 {'log_file': 'checkpoints/2021-01-07T2235_full/log.log', 'tensorboard': False, 'tensorboard_logdir': 'tensorboard_logdir', 'init_checkpoint': 'bert-base-uncased', 'data_dir': 'data/canonical_data/bert_base_uncased_lower', 'data_sort_on': False, 'name': 'farmer', 'task_def': 'experiments/glue/glue_task_def.yml', 'train_datasets': ['mnli', 'rte', 'qqp', 'qnli', 'mrpc', 'sst', 'cola', 'stsb'], 'test_datasets': ['mnli_matched', 'mnli_mismatched', 'rte', 'qqp', 'qnli', 'mrpc', 'sst', 'cola', 'stsb'], 'glue_format_on': False, 'mkd_opt': 0, 'do_padding': False, 'update_bert_opt': 0, 'multi_gpu_on': True, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'max_answer_len': 10, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': 1, 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'encoder_type': <EncoderModelType.BERT: 1>, 'num_hidden_layers': -1, 'bert_model_type': 'bert-base-uncased', 'do_lower_case': False, 'masked_lm_prob': 0.15, 'short_seq_prob': 0.2, 'max_predictions_per_seq': 128, 'bin_on': False, 'bin_size': 64, 'bin_grow_ratio': 0.5, 'cuda': True, 'log_per_updates': 500, 'save_per_updates': 10000, 'save_per_updates_on': False, 'epochs': 5, 'batch_size': 8, 'batch_size_eval': 8, 'optimizer': 'adamax', 'grad_clipping': 0.0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 5e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'adam_eps': 1e-06, 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'model_ckpt': 'checkpoints/model_0.pt', 'resume': False, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'lr_gamma': 0.5, 'scheduler_type': 'ms', 'output_dir': 'checkpoints/2021-01-07T2235_full', 'seed': 2018, 'grad_accumulation_step': 2, 'fp16': False, 'fp16_opt_level': 'O1', 'adv_train': False, 'adv_opt': 0, 'adv_norm_level': 0, 'adv_p_norm': 'inf', 'adv_alpha': 1, 'adv_k': 1, 'adv_step_size': 0.001, 'adv_noise_var': 1e-05, 'adv_epsilon': 1e-06, 'loss_pred': True, 'collect_uncertainty': None, 'collect_topk': 0.1, 'load_ranked_data': None, 'mc_dropout': 0, 'finetune': False, 'encode_mode': False, 'task_def_list': [{'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7f9553cd94f0>', 'n_class': '3', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>,)', 'split_names': "['train', 'matched_dev', 'mismatched_dev', 'matched_test', 'mismatched_test']", 'enable_san': 'False', 'dropout_p': '0.1', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7f94c2f23460>', 'n_class': '2', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>,)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.F1: 1>)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7f94c2f233d0>', 'n_class': '2', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>,)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.F1: 1>)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseOnly: 1>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>,)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseOnly: 1>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.MCC: 2>)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': '0.05', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'self': '{}', 'label_vocab': 'None', 'n_class': '1', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'task_type': '<TaskType.Regression: 2>', 'metric_meta': '(<Metric.Pearson: 3>, <Metric.Spearman: 4>)', 'split_names': "['train', 'dev', 'test']", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.MseCriterion: 1>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.MseCriterion: 1>', '__class__': "<class 'experiments.exp_def.TaskDef'>"}]}
01/07/2021 10:36:27 ####################
01/07/2021 10:36:27 ############# Gradient Accumulation Info #############
01/07/2021 10:36:27 number of step: 595515
01/07/2021 10:36:27 number of grad grad_accumulation step: 2
01/07/2021 10:36:27 adjusted number of step: 297757
01/07/2021 10:36:27 ############# Gradient Accumulation Info #############
01/07/2021 10:36:40 
############# Model Arch of MT-DNN #############
SANBertNetwork(
  (dropout_list): ModuleList(
    (0): DropoutWrapper()
    (1): DropoutWrapper()
    (2): DropoutWrapper()
    (3): DropoutWrapper()
    (4): DropoutWrapper()
    (5): DropoutWrapper()
    (6): DropoutWrapper()
    (7): DropoutWrapper()
  )
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (loss_pred_fc): Linear(in_features=768, out_features=1, bias=True)
  (scoring_list): ModuleList(
    (0): Linear(in_features=768, out_features=3, bias=True)
    (1): Linear(in_features=768, out_features=2, bias=True)
    (2): Linear(in_features=768, out_features=2, bias=True)
    (3): Linear(in_features=768, out_features=2, bias=True)
    (4): Linear(in_features=768, out_features=2, bias=True)
    (5): Linear(in_features=768, out_features=2, bias=True)
    (6): Linear(in_features=768, out_features=2, bias=True)
    (7): Linear(in_features=768, out_features=1, bias=True)
  )
)

01/07/2021 10:36:40 Total number of params: 109495313
01/07/2021 10:36:40 At epoch 0
01/07/2021 10:36:40 Task [ 3] updates[     0] train loss[0.86763] remaining[6:49:27]
01/07/2021 10:38:12 Task [ 0] updates[   500] train loss[0.93959] remaining[3:01:12]
01/07/2021 10:39:39 Task [ 0] updates[  1000] train loss[0.97835] remaining[2:53:58]
01/07/2021 10:41:02 Task [ 2] updates[  1500] train loss[0.96634] remaining[2:48:41]
01/07/2021 10:42:30 Task [ 2] updates[  2000] train loss[0.95263] remaining[2:47:39]
01/07/2021 10:43:58 Task [ 2] updates[  2500] train loss[0.94030] remaining[2:46:19]
01/07/2021 10:45:26 Task [ 2] updates[  3000] train loss[0.92483] remaining[2:45:03]
01/07/2021 10:46:51 Task [ 0] updates[  3500] train loss[0.92344] remaining[2:42:59]
01/07/2021 10:48:15 Task [ 3] updates[  4000] train loss[0.91959] remaining[2:40:41]
01/07/2021 10:49:40 Task [ 2] updates[  4500] train loss[0.90691] remaining[2:38:58]
01/07/2021 10:51:06 Task [ 3] updates[  5000] train loss[0.89158] remaining[2:37:26]
01/07/2021 10:52:31 Task [ 0] updates[  5500] train loss[0.87353] remaining[2:35:43]
01/07/2021 10:53:57 Task [ 5] updates[  6000] train loss[0.85752] remaining[2:34:13]
01/07/2021 10:55:24 Task [ 2] updates[  6500] train loss[0.84308] remaining[2:32:50]
01/07/2021 10:56:51 Task [ 2] updates[  7000] train loss[0.82997] remaining[2:31:31]
01/07/2021 10:58:20 Task [ 0] updates[  7500] train loss[0.81624] remaining[2:30:17]
01/07/2021 10:59:44 Task [ 0] updates[  8000] train loss[0.80281] remaining[2:28:39]
01/07/2021 11:01:11 Task [ 0] updates[  8500] train loss[0.78916] remaining[2:27:15]
01/07/2021 11:02:37 Task [ 3] updates[  9000] train loss[0.77694] remaining[2:25:44]
01/07/2021 11:04:05 Task [ 0] updates[  9500] train loss[0.76567] remaining[2:24:23]
01/07/2021 11:05:31 Task [ 5] updates[ 10000] train loss[0.75495] remaining[2:22:56]
01/07/2021 11:06:58 Task [ 2] updates[ 10500] train loss[0.74506] remaining[2:21:31]
01/07/2021 11:08:23 Task [ 3] updates[ 11000] train loss[0.73505] remaining[2:19:57]
01/07/2021 11:09:49 Task [ 2] updates[ 11500] train loss[0.72581] remaining[2:18:28]
01/07/2021 11:11:14 Task [ 2] updates[ 12000] train loss[0.71672] remaining[2:16:56]
01/07/2021 11:12:40 Task [ 5] updates[ 12500] train loss[0.70822] remaining[2:15:28]
01/07/2021 11:14:05 Task [ 0] updates[ 13000] train loss[0.70014] remaining[2:13:58]
01/07/2021 11:15:30 Task [ 2] updates[ 13500] train loss[0.69215] remaining[2:12:26]
01/07/2021 11:16:54 Task [ 3] updates[ 14000] train loss[0.68475] remaining[2:10:53]
01/07/2021 11:18:21 Task [ 0] updates[ 14500] train loss[0.67818] remaining[2:09:28]
01/07/2021 11:19:46 Task [ 0] updates[ 15000] train loss[0.67211] remaining[2:08:00]
01/07/2021 11:21:11 Task [ 0] updates[ 15500] train loss[0.66612] remaining[2:06:30]
01/07/2021 11:22:36 Task [ 2] updates[ 16000] train loss[0.66018] remaining[2:05:00]
01/07/2021 11:24:02 Task [ 0] updates[ 16500] train loss[0.65473] remaining[2:03:33]
01/07/2021 11:25:30 Task [ 2] updates[ 17000] train loss[0.64955] remaining[2:02:12]
01/07/2021 11:26:55 Task [ 0] updates[ 17500] train loss[0.64437] remaining[2:00:44]
01/07/2021 11:28:20 Task [ 0] updates[ 18000] train loss[0.63896] remaining[1:59:14]
01/07/2021 11:29:44 Task [ 2] updates[ 18500] train loss[0.63415] remaining[1:57:45]
01/07/2021 11:31:09 Task [ 2] updates[ 19000] train loss[0.62951] remaining[1:56:17]
01/07/2021 11:32:36 Task [ 2] updates[ 19500] train loss[0.62517] remaining[1:54:51]
01/07/2021 11:34:00 Task [ 2] updates[ 20000] train loss[0.62061] remaining[1:53:22]
01/07/2021 11:35:24 Task [ 2] updates[ 20500] train loss[0.61642] remaining[1:51:52]
01/07/2021 11:36:50 Task [ 0] updates[ 21000] train loss[0.61264] remaining[1:50:27]
01/07/2021 11:38:17 Task [ 2] updates[ 21500] train loss[0.60881] remaining[1:49:02]
01/07/2021 11:39:42 Task [ 0] updates[ 22000] train loss[0.60559] remaining[1:47:34]
01/07/2021 11:41:07 Task [ 5] updates[ 22500] train loss[0.60226] remaining[1:46:07]
01/07/2021 11:42:33 Task [ 5] updates[ 23000] train loss[0.59841] remaining[1:44:42]
01/07/2021 11:43:59 Task [ 5] updates[ 23500] train loss[0.59479] remaining[1:43:16]
01/07/2021 11:45:26 Task [ 0] updates[ 24000] train loss[0.59149] remaining[1:41:52]
01/07/2021 11:46:52 Task [ 2] updates[ 24500] train loss[0.58845] remaining[1:40:25]
01/07/2021 11:48:18 Task [ 0] updates[ 25000] train loss[0.58518] remaining[1:38:59]
01/07/2021 11:49:42 Task [ 3] updates[ 25500] train loss[0.58243] remaining[1:37:31]
01/07/2021 11:51:03 Task [ 5] updates[ 26000] train loss[0.57932] remaining[1:35:58]
01/07/2021 11:52:15 Task [ 0] updates[ 26500] train loss[0.57656] remaining[1:34:15]
01/07/2021 11:53:36 Task [ 2] updates[ 27000] train loss[0.57387] remaining[1:32:44]
01/07/2021 11:55:03 Task [ 2] updates[ 27500] train loss[0.57117] remaining[1:31:20]
01/07/2021 11:56:28 Task [ 0] updates[ 28000] train loss[0.56881] remaining[1:29:54]
01/07/2021 11:57:54 Task [ 2] updates[ 28500] train loss[0.56631] remaining[1:28:29]
01/07/2021 11:59:20 Task [ 2] updates[ 29000] train loss[0.56395] remaining[1:27:05]
01/08/2021 12:00:48 Task [ 3] updates[ 29500] train loss[0.56141] remaining[1:25:42]
01/08/2021 12:02:13 Task [ 0] updates[ 30000] train loss[0.55920] remaining[1:24:16]
01/08/2021 12:03:38 Task [ 0] updates[ 30500] train loss[0.55660] remaining[1:22:49]
01/08/2021 12:05:03 Task [ 0] updates[ 31000] train loss[0.55449] remaining[1:21:24]
01/08/2021 12:06:28 Task [ 2] updates[ 31500] train loss[0.55203] remaining[1:19:57]
01/08/2021 12:07:52 Task [ 2] updates[ 32000] train loss[0.54960] remaining[1:18:30]
01/08/2021 12:09:18 Task [ 4] updates[ 32500] train loss[0.54774] remaining[1:17:05]
01/08/2021 12:10:42 Task [ 0] updates[ 33000] train loss[0.54583] remaining[1:15:39]
01/08/2021 12:12:07 Task [ 2] updates[ 33500] train loss[0.54397] remaining[1:14:13]
01/08/2021 12:13:32 Task [ 0] updates[ 34000] train loss[0.54191] remaining[1:12:47]
01/08/2021 12:14:58 Task [ 2] updates[ 34500] train loss[0.53975] remaining[1:11:22]
01/08/2021 12:16:22 Task [ 0] updates[ 35000] train loss[0.53782] remaining[1:09:56]
01/08/2021 12:17:47 Task [ 2] updates[ 35500] train loss[0.53597] remaining[1:08:30]
01/08/2021 12:19:15 Task [ 2] updates[ 36000] train loss[0.53417] remaining[1:07:06]
01/08/2021 12:20:41 Task [ 2] updates[ 36500] train loss[0.53236] remaining[1:05:41]
01/08/2021 12:22:06 Task [ 2] updates[ 37000] train loss[0.53061] remaining[1:04:15]
01/08/2021 12:23:32 Task [ 2] updates[ 37500] train loss[0.52897] remaining[1:02:50]
01/08/2021 12:25:00 Task [ 0] updates[ 38000] train loss[0.52706] remaining[1:01:26]
01/08/2021 12:26:24 Task [ 2] updates[ 38500] train loss[0.52540] remaining[1:00:00]
01/08/2021 12:27:49 Task [ 3] updates[ 39000] train loss[0.52359] remaining[0:58:34]
01/08/2021 12:29:15 Task [ 0] updates[ 39500] train loss[0.52215] remaining[0:57:08]
01/08/2021 12:30:40 Task [ 2] updates[ 40000] train loss[0.52053] remaining[0:55:43]
01/08/2021 12:32:05 Task [ 0] updates[ 40500] train loss[0.51880] remaining[0:54:17]
01/08/2021 12:33:29 Task [ 0] updates[ 41000] train loss[0.51733] remaining[0:52:51]
01/08/2021 12:34:56 Task [ 3] updates[ 41500] train loss[0.51586] remaining[0:51:26]
01/08/2021 12:36:19 Task [ 2] updates[ 42000] train loss[0.51451] remaining[0:50:00]
01/08/2021 12:37:45 Task [ 0] updates[ 42500] train loss[0.51293] remaining[0:48:34]
01/08/2021 12:39:11 Task [ 2] updates[ 43000] train loss[0.51151] remaining[0:47:09]
01/08/2021 12:40:36 Task [ 0] updates[ 43500] train loss[0.51005] remaining[0:45:43]
01/08/2021 12:42:01 Task [ 2] updates[ 44000] train loss[0.50851] remaining[0:44:18]
01/08/2021 12:43:27 Task [ 0] updates[ 44500] train loss[0.50715] remaining[0:42:52]
01/08/2021 12:44:51 Task [ 3] updates[ 45000] train loss[0.50602] remaining[0:41:26]
01/08/2021 12:46:05 Task [ 0] updates[ 45500] train loss[0.50477] remaining[0:39:57]
01/08/2021 12:47:30 Task [ 3] updates[ 46000] train loss[0.50341] remaining[0:38:32]
01/08/2021 12:48:56 Task [ 0] updates[ 46500] train loss[0.50200] remaining[0:37:07]
01/08/2021 12:50:21 Task [ 2] updates[ 47000] train loss[0.50067] remaining[0:35:41]
01/08/2021 12:51:47 Task [ 2] updates[ 47500] train loss[0.49941] remaining[0:34:16]
01/08/2021 12:53:12 Task [ 0] updates[ 48000] train loss[0.49818] remaining[0:32:51]
01/08/2021 12:54:37 Task [ 0] updates[ 48500] train loss[0.49691] remaining[0:31:26]
01/08/2021 12:56:04 Task [ 2] updates[ 49000] train loss[0.49578] remaining[0:30:00]
01/08/2021 12:57:28 Task [ 2] updates[ 49500] train loss[0.49465] remaining[0:28:35]
01/08/2021 12:58:55 Task [ 0] updates[ 50000] train loss[0.49344] remaining[0:27:10]
01/08/2021 01:00:09 Task [ 0] updates[ 50500] train loss[0.49225] remaining[0:25:42]
01/08/2021 01:01:21 Task [ 2] updates[ 51000] train loss[0.49105] remaining[0:24:15]
01/08/2021 01:02:33 Task [ 3] updates[ 51500] train loss[0.48998] remaining[0:22:48]
01/08/2021 01:03:45 Task [ 6] updates[ 52000] train loss[0.48865] remaining[0:21:21]
01/08/2021 01:04:57 Task [ 0] updates[ 52500] train loss[0.48757] remaining[0:19:54]
01/08/2021 01:06:10 Task [ 0] updates[ 53000] train loss[0.48658] remaining[0:18:28]
01/08/2021 01:07:22 Task [ 2] updates[ 53500] train loss[0.48574] remaining[0:17:02]
01/08/2021 01:08:34 Task [ 2] updates[ 54000] train loss[0.48466] remaining[0:15:36]
01/08/2021 01:09:47 Task [ 3] updates[ 54500] train loss[0.48363] remaining[0:14:11]
01/08/2021 01:10:59 Task [ 0] updates[ 55000] train loss[0.48270] remaining[0:12:46]
01/08/2021 01:12:17 Task [ 0] updates[ 55500] train loss[0.48175] remaining[0:11:21]
01/08/2021 01:13:42 Task [ 0] updates[ 56000] train loss[0.48067] remaining[0:09:57]
01/08/2021 01:15:10 Task [ 0] updates[ 56500] train loss[0.47956] remaining[0:08:33]
01/08/2021 01:16:37 Task [ 3] updates[ 57000] train loss[0.47871] remaining[0:07:09]
01/08/2021 01:18:03 Task [ 0] updates[ 57500] train loss[0.47764] remaining[0:05:45]
01/08/2021 01:19:29 Task [ 0] updates[ 58000] train loss[0.47662] remaining[0:04:21]
01/08/2021 01:20:54 Task [ 2] updates[ 58500] train loss[0.47565] remaining[0:02:57]
01/08/2021 01:22:18 Task [ 2] updates[ 59000] train loss[0.47475] remaining[0:01:32]
01/08/2021 01:23:44 Task [ 2] updates[ 59500] train loss[0.47383] remaining[0:00:08]
01/08/2021 01:24:16 Task mnli_matched -- epoch 0 -- Dev ACC: 81.966
01/08/2021 01:24:40 [new test scores saved.]
01/08/2021 01:25:04 Task mnli_mismatched -- epoch 0 -- Dev ACC: 82.109
01/08/2021 01:25:28 [new test scores saved.]
01/08/2021 01:25:29 Task rte -- epoch 0 -- Dev ACC: 72.563
01/08/2021 01:25:38 [new test scores saved.]
01/08/2021 01:27:02 Task qqp -- epoch 0 -- Dev ACC: 87.947
01/08/2021 01:27:02 Task qqp -- epoch 0 -- Dev F1: 82.717
01/08/2021 01:40:39 [new test scores saved.]
01/08/2021 01:40:54 Task qnli -- epoch 0 -- Dev ACC: 85.206
01/08/2021 01:41:11 [new test scores saved.]
01/08/2021 01:41:12 Task mrpc -- epoch 0 -- Dev ACC: 77.451
01/08/2021 01:41:12 Task mrpc -- epoch 0 -- Dev F1: 84.718
01/08/2021 01:41:16 [new test scores saved.]
01/08/2021 01:41:18 Task sst -- epoch 0 -- Dev ACC: 92.087
01/08/2021 01:41:21 [new test scores saved.]
01/08/2021 01:41:23 Task cola -- epoch 0 -- Dev ACC: 73.058
01/08/2021 01:41:23 Task cola -- epoch 0 -- Dev MCC: 28.953
01/08/2021 01:41:25 [new test scores saved.]
01/08/2021 01:41:28 Task stsb -- epoch 0 -- Dev Pearson: 86.008
01/08/2021 01:41:28 Task stsb -- epoch 0 -- Dev Spearman: 86.837
01/08/2021 01:41:30 [new test scores saved.]
01/08/2021 01:41:35 At epoch 1
01/08/2021 01:42:51 Task [ 0] updates[ 60000] train loss[0.47300] remaining[2:45:51]
01/08/2021 01:44:16 Task [ 0] updates[ 60500] train loss[0.47207] remaining[2:45:59]
01/08/2021 01:45:40 Task [ 2] updates[ 61000] train loss[0.47112] remaining[2:43:55]
01/08/2021 01:47:06 Task [ 3] updates[ 61500] train loss[0.47037] remaining[2:43:14]
01/08/2021 01:48:31 Task [ 2] updates[ 62000] train loss[0.46951] remaining[2:41:44]
01/08/2021 01:49:58 Task [ 2] updates[ 62500] train loss[0.46857] remaining[2:40:45]
01/08/2021 01:51:25 Task [ 2] updates[ 63000] train loss[0.46769] remaining[2:39:59]
01/08/2021 01:52:51 Task [ 3] updates[ 63500] train loss[0.46690] remaining[2:38:31]
01/08/2021 01:54:14 Task [ 2] updates[ 64000] train loss[0.46614] remaining[2:36:39]
01/08/2021 01:55:38 Task [ 2] updates[ 64500] train loss[0.46542] remaining[2:35:04]
01/08/2021 01:57:04 Task [ 5] updates[ 65000] train loss[0.46465] remaining[2:33:45]
01/08/2021 01:58:29 Task [ 0] updates[ 65500] train loss[0.46395] remaining[2:32:14]
01/08/2021 01:59:53 Task [ 0] updates[ 66000] train loss[0.46316] remaining[2:30:41]
01/08/2021 02:01:18 Task [ 0] updates[ 66500] train loss[0.46237] remaining[2:29:15]
01/08/2021 02:02:44 Task [ 2] updates[ 67000] train loss[0.46159] remaining[2:27:58]
01/08/2021 02:04:10 Task [ 0] updates[ 67500] train loss[0.46083] remaining[2:26:33]
01/08/2021 02:05:36 Task [ 0] updates[ 68000] train loss[0.46012] remaining[2:25:14]
01/08/2021 02:07:03 Task [ 2] updates[ 68500] train loss[0.45939] remaining[2:24:01]
01/08/2021 02:08:27 Task [ 0] updates[ 69000] train loss[0.45853] remaining[2:22:28]
01/08/2021 02:09:43 Task [ 0] updates[ 69500] train loss[0.45776] remaining[2:20:13]
01/08/2021 02:10:58 Task [ 0] updates[ 70000] train loss[0.45695] remaining[2:18:06]
01/08/2021 02:12:16 Task [ 0] updates[ 70500] train loss[0.45617] remaining[2:16:14]
01/08/2021 02:13:42 Task [ 2] updates[ 71000] train loss[0.45539] remaining[2:14:55]
01/08/2021 02:15:08 Task [ 0] updates[ 71500] train loss[0.45457] remaining[2:13:40]
01/08/2021 02:16:35 Task [ 2] updates[ 72000] train loss[0.45375] remaining[2:12:24]
01/08/2021 02:17:59 Task [ 2] updates[ 72500] train loss[0.45293] remaining[2:10:59]
01/08/2021 02:19:23 Task [ 3] updates[ 73000] train loss[0.45207] remaining[2:09:34]
01/08/2021 02:20:48 Task [ 0] updates[ 73500] train loss[0.45133] remaining[2:08:13]
01/08/2021 02:22:15 Task [ 0] updates[ 74000] train loss[0.45058] remaining[2:06:55]
01/08/2021 02:23:40 Task [ 0] updates[ 74500] train loss[0.44995] remaining[2:05:33]
01/08/2021 02:25:06 Task [ 0] updates[ 75000] train loss[0.44920] remaining[2:04:13]
01/08/2021 02:26:30 Task [ 2] updates[ 75500] train loss[0.44841] remaining[2:02:47]
01/08/2021 02:27:55 Task [ 2] updates[ 76000] train loss[0.44766] remaining[2:01:24]
01/08/2021 02:29:19 Task [ 0] updates[ 76500] train loss[0.44696] remaining[1:59:59]
01/08/2021 02:30:46 Task [ 2] updates[ 77000] train loss[0.44624] remaining[1:58:40]
01/08/2021 02:32:13 Task [ 3] updates[ 77500] train loss[0.44546] remaining[1:57:21]
01/08/2021 02:33:37 Task [ 3] updates[ 78000] train loss[0.44469] remaining[1:55:55]
01/08/2021 02:35:02 Task [ 0] updates[ 78500] train loss[0.44390] remaining[1:54:31]
01/08/2021 02:36:28 Task [ 3] updates[ 79000] train loss[0.44323] remaining[1:53:09]
01/08/2021 02:37:52 Task [ 2] updates[ 79500] train loss[0.44245] remaining[1:51:43]
01/08/2021 02:39:15 Task [ 3] updates[ 80000] train loss[0.44170] remaining[1:50:16]
01/08/2021 02:40:39 Task [ 0] updates[ 80500] train loss[0.44099] remaining[1:48:51]
01/08/2021 02:42:05 Task [ 0] updates[ 81000] train loss[0.44025] remaining[1:47:27]
01/08/2021 02:43:28 Task [ 2] updates[ 81500] train loss[0.43950] remaining[1:46:00]
01/08/2021 02:44:53 Task [ 3] updates[ 82000] train loss[0.43874] remaining[1:44:37]
01/08/2021 02:46:19 Task [ 0] updates[ 82500] train loss[0.43797] remaining[1:43:15]
01/08/2021 02:50:39 Task [ 0] updates[ 83000] train loss[0.43719] remaining[1:46:19]
01/08/2021 02:52:02 Task [ 3] updates[ 83500] train loss[0.43644] remaining[1:44:44]
01/08/2021 02:53:27 Task [ 0] updates[ 84000] train loss[0.43565] remaining[1:43:10]
01/08/2021 02:54:51 Task [ 2] updates[ 84500] train loss[0.43487] remaining[1:41:37]
01/08/2021 02:56:17 Task [ 3] updates[ 85000] train loss[0.43414] remaining[1:40:05]
01/08/2021 02:57:39 Task [ 0] updates[ 85500] train loss[0.43345] remaining[1:38:30]
01/08/2021 02:59:05 Task [ 3] updates[ 86000] train loss[0.43276] remaining[1:36:59]
01/08/2021 03:00:29 Task [ 0] updates[ 86500] train loss[0.43197] remaining[1:35:27]
01/08/2021 03:01:54 Task [ 2] updates[ 87000] train loss[0.43126] remaining[1:33:55]
01/08/2021 03:03:18 Task [ 2] updates[ 87500] train loss[0.43048] remaining[1:32:24]
01/08/2021 03:04:42 Task [ 0] updates[ 88000] train loss[0.42976] remaining[1:30:52]
01/08/2021 03:06:10 Task [ 3] updates[ 88500] train loss[0.42903] remaining[1:29:25]
01/08/2021 03:07:33 Task [ 0] updates[ 89000] train loss[0.42825] remaining[1:27:52]
01/08/2021 03:08:56 Task [ 5] updates[ 89500] train loss[0.42753] remaining[1:26:20]
01/08/2021 03:10:22 Task [ 5] updates[ 90000] train loss[0.42679] remaining[1:24:51]
01/08/2021 03:11:47 Task [ 5] updates[ 90500] train loss[0.42601] remaining[1:23:22]
01/08/2021 03:13:12 Task [ 2] updates[ 91000] train loss[0.42524] remaining[1:21:52]
01/08/2021 03:14:37 Task [ 2] updates[ 91500] train loss[0.42447] remaining[1:20:22]
01/08/2021 03:16:02 Task [ 0] updates[ 92000] train loss[0.42382] remaining[1:18:53]
01/08/2021 03:17:23 Task [ 0] updates[ 92500] train loss[0.42316] remaining[1:17:21]
01/08/2021 03:18:48 Task [ 0] updates[ 93000] train loss[0.42254] remaining[1:15:52]
01/08/2021 03:20:13 Task [ 0] updates[ 93500] train loss[0.42186] remaining[1:14:22]
01/08/2021 03:21:37 Task [ 2] updates[ 94000] train loss[0.42109] remaining[1:12:53]
01/08/2021 03:23:01 Task [ 2] updates[ 94500] train loss[0.42042] remaining[1:11:24]
01/08/2021 03:24:27 Task [ 2] updates[ 95000] train loss[0.41978] remaining[1:09:56]
01/08/2021 03:25:51 Task [ 0] updates[ 95500] train loss[0.41906] remaining[1:08:27]
01/08/2021 03:27:25 Task [ 0] updates[ 96000] train loss[0.41837] remaining[1:07:05]
01/08/2021 03:28:59 Task [ 5] updates[ 96500] train loss[0.41778] remaining[1:05:41]
01/08/2021 03:30:22 Task [ 0] updates[ 97000] train loss[0.41715] remaining[1:04:12]
01/08/2021 03:31:45 Task [ 2] updates[ 97500] train loss[0.41644] remaining[1:02:42]
01/08/2021 03:33:08 Task [ 0] updates[ 98000] train loss[0.41575] remaining[1:01:13]
01/08/2021 03:34:34 Task [ 3] updates[ 98500] train loss[0.41508] remaining[0:59:46]
01/08/2021 03:35:57 Task [ 3] updates[ 99000] train loss[0.41450] remaining[0:58:16]
01/08/2021 03:37:19 Task [ 0] updates[ 99500] train loss[0.41392] remaining[0:56:47]
01/08/2021 03:38:44 Task [ 4] updates[100000] train loss[0.41321] remaining[0:55:19]
01/08/2021 03:40:09 Task [ 0] updates[100500] train loss[0.41267] remaining[0:53:51]
01/08/2021 03:41:35 Task [ 5] updates[101000] train loss[0.41206] remaining[0:52:24]
01/08/2021 03:42:59 Task [ 0] updates[101500] train loss[0.41144] remaining[0:50:56]
01/08/2021 03:44:24 Task [ 3] updates[102000] train loss[0.41083] remaining[0:49:28]
01/08/2021 03:45:49 Task [ 2] updates[102500] train loss[0.41021] remaining[0:48:01]
01/08/2021 03:47:14 Task [ 2] updates[103000] train loss[0.40957] remaining[0:46:34]
01/08/2021 03:48:37 Task [ 5] updates[103500] train loss[0.40897] remaining[0:45:05]
01/08/2021 03:50:01 Task [ 3] updates[104000] train loss[0.40835] remaining[0:43:38]
01/08/2021 03:51:25 Task [ 0] updates[104500] train loss[0.40780] remaining[0:42:10]
01/08/2021 03:52:49 Task [ 2] updates[105000] train loss[0.40726] remaining[0:40:43]
01/08/2021 03:54:12 Task [ 2] updates[105500] train loss[0.40667] remaining[0:39:15]
01/08/2021 03:55:38 Task [ 2] updates[106000] train loss[0.40610] remaining[0:37:48]
01/08/2021 04:00:05 Task [ 5] updates[106500] train loss[0.40549] remaining[0:37:10]
01/08/2021 04:01:33 Task [ 0] updates[107000] train loss[0.40496] remaining[0:35:42]
01/08/2021 04:03:01 Task [ 2] updates[107500] train loss[0.40440] remaining[0:34:13]
01/08/2021 04:04:30 Task [ 0] updates[108000] train loss[0.40385] remaining[0:32:45]
01/08/2021 04:05:53 Task [ 0] updates[108500] train loss[0.40333] remaining[0:31:15]
01/08/2021 04:07:19 Task [ 0] updates[109000] train loss[0.40271] remaining[0:29:46]
01/08/2021 04:08:44 Task [ 0] updates[109500] train loss[0.40218] remaining[0:28:17]
01/08/2021 04:10:12 Task [ 0] updates[110000] train loss[0.40162] remaining[0:26:48]
01/08/2021 04:11:39 Task [ 2] updates[110500] train loss[0.40107] remaining[0:25:20]
01/08/2021 04:13:06 Task [ 3] updates[111000] train loss[0.40054] remaining[0:23:51]
01/08/2021 04:14:34 Task [ 0] updates[111500] train loss[0.39996] remaining[0:22:23]
01/08/2021 04:16:01 Task [ 2] updates[112000] train loss[0.39938] remaining[0:20:54]
01/08/2021 04:17:27 Task [ 3] updates[112500] train loss[0.39887] remaining[0:19:26]
01/08/2021 04:18:53 Task [ 2] updates[113000] train loss[0.39839] remaining[0:17:57]
01/08/2021 04:20:19 Task [ 0] updates[113500] train loss[0.39782] remaining[0:16:29]
01/08/2021 04:21:40 Task [ 0] updates[114000] train loss[0.39738] remaining[0:15:00]
01/08/2021 04:22:54 Task [ 0] updates[114500] train loss[0.39684] remaining[0:13:30]
01/08/2021 04:24:17 Task [ 2] updates[115000] train loss[0.39637] remaining[0:12:02]
01/08/2021 04:25:44 Task [ 3] updates[115500] train loss[0.39584] remaining[0:10:34]
01/08/2021 04:27:11 Task [ 0] updates[116000] train loss[0.39532] remaining[0:09:06]
01/08/2021 04:28:38 Task [ 0] updates[116500] train loss[0.39482] remaining[0:07:38]
01/08/2021 04:30:04 Task [ 5] updates[117000] train loss[0.39428] remaining[0:06:10]
01/08/2021 04:31:30 Task [ 2] updates[117500] train loss[0.39371] remaining[0:04:42]
01/08/2021 04:32:55 Task [ 0] updates[118000] train loss[0.39319] remaining[0:03:13]
01/08/2021 04:34:21 Task [ 0] updates[118500] train loss[0.39271] remaining[0:01:46]
01/08/2021 04:35:48 Task [ 7] updates[119000] train loss[0.39223] remaining[0:00:18]
01/08/2021 04:36:29 Task mnli_matched -- epoch 1 -- Dev ACC: 83.678
01/08/2021 04:36:53 [new test scores saved.]
01/08/2021 04:37:17 Task mnli_mismatched -- epoch 1 -- Dev ACC: 84.032
01/08/2021 04:37:42 [new test scores saved.]
01/08/2021 04:37:43 Task rte -- epoch 1 -- Dev ACC: 74.729
01/08/2021 04:37:52 [new test scores saved.]
01/08/2021 04:39:17 Task qqp -- epoch 1 -- Dev ACC: 89.874
01/08/2021 04:39:17 Task qqp -- epoch 1 -- Dev F1: 86.347
01/08/2021 04:53:00 [new test scores saved.]
01/08/2021 04:53:15 Task qnli -- epoch 1 -- Dev ACC: 86.881
01/08/2021 04:53:32 [new test scores saved.]
01/08/2021 04:53:33 Task mrpc -- epoch 1 -- Dev ACC: 78.431
01/08/2021 04:53:33 Task mrpc -- epoch 1 -- Dev F1: 85.430
01/08/2021 04:53:38 [new test scores saved.]
01/08/2021 04:53:39 Task sst -- epoch 1 -- Dev ACC: 92.087
01/08/2021 04:53:43 [new test scores saved.]
01/08/2021 04:53:44 Task cola -- epoch 1 -- Dev ACC: 78.044
01/08/2021 04:53:44 Task cola -- epoch 1 -- Dev MCC: 44.715
01/08/2021 04:53:46 [new test scores saved.]
01/08/2021 04:53:49 Task stsb -- epoch 1 -- Dev Pearson: 87.099
01/08/2021 04:53:49 Task stsb -- epoch 1 -- Dev Spearman: 87.607
01/08/2021 04:53:52 [new test scores saved.]
01/08/2021 04:53:56 At epoch 2
01/08/2021 04:55:05 Task [ 0] updates[119500] train loss[0.39174] remaining[2:50:32]
01/08/2021 04:56:31 Task [ 3] updates[120000] train loss[0.39123] remaining[2:48:40]
01/08/2021 04:57:56 Task [ 0] updates[120500] train loss[0.39071] remaining[2:46:16]
01/08/2021 04:59:20 Task [ 0] updates[121000] train loss[0.39030] remaining[2:43:46]
01/08/2021 05:00:46 Task [ 3] updates[121500] train loss[0.38984] remaining[2:42:38]
01/08/2021 05:02:12 Task [ 0] updates[122000] train loss[0.38933] remaining[2:41:28]
01/08/2021 05:03:36 Task [ 0] updates[122500] train loss[0.38881] remaining[2:39:37]
01/08/2021 05:05:01 Task [ 3] updates[123000] train loss[0.38838] remaining[2:38:13]
01/08/2021 05:06:24 Task [ 2] updates[123500] train loss[0.38793] remaining[2:36:17]
01/08/2021 05:07:49 Task [ 0] updates[124000] train loss[0.38754] remaining[2:34:49]
01/08/2021 05:09:15 Task [ 2] updates[124500] train loss[0.38706] remaining[2:33:40]
01/08/2021 05:10:40 Task [ 2] updates[125000] train loss[0.38666] remaining[2:32:14]
01/08/2021 05:12:04 Task [ 5] updates[125500] train loss[0.38625] remaining[2:30:39]
01/08/2021 05:13:27 Task [ 0] updates[126000] train loss[0.38582] remaining[2:28:55]
01/08/2021 05:14:52 Task [ 0] updates[126500] train loss[0.38538] remaining[2:27:32]
01/08/2021 05:16:17 Task [ 2] updates[127000] train loss[0.38493] remaining[2:26:10]
01/08/2021 05:17:43 Task [ 2] updates[127500] train loss[0.38451] remaining[2:24:49]
01/08/2021 05:19:07 Task [ 2] updates[128000] train loss[0.38406] remaining[2:23:21]
01/08/2021 05:20:32 Task [ 0] updates[128500] train loss[0.38362] remaining[2:21:56]
01/08/2021 05:21:43 Task [ 0] updates[129000] train loss[0.38312] remaining[2:19:24]
01/08/2021 05:23:01 Task [ 2] updates[129500] train loss[0.38270] remaining[2:17:29]
01/08/2021 05:24:27 Task [ 0] updates[130000] train loss[0.38223] remaining[2:16:12]
01/08/2021 05:25:53 Task [ 5] updates[130500] train loss[0.38179] remaining[2:14:57]
01/08/2021 05:27:17 Task [ 3] updates[131000] train loss[0.38132] remaining[2:13:34]
01/08/2021 05:28:42 Task [ 0] updates[131500] train loss[0.38090] remaining[2:12:13]
01/08/2021 05:30:05 Task [ 2] updates[132000] train loss[0.38041] remaining[2:10:46]
01/08/2021 05:31:30 Task [ 0] updates[132500] train loss[0.37997] remaining[2:09:22]
01/08/2021 05:32:54 Task [ 2] updates[133000] train loss[0.37950] remaining[2:07:58]
01/08/2021 05:34:18 Task [ 0] updates[133500] train loss[0.37904] remaining[2:06:34]
01/08/2021 05:35:43 Task [ 0] updates[134000] train loss[0.37866] remaining[2:05:14]
01/08/2021 05:37:07 Task [ 0] updates[134500] train loss[0.37824] remaining[2:03:49]
01/08/2021 05:38:31 Task [ 5] updates[135000] train loss[0.37780] remaining[2:02:25]
01/08/2021 05:39:56 Task [ 2] updates[135500] train loss[0.37737] remaining[2:01:02]
01/08/2021 05:41:19 Task [ 0] updates[136000] train loss[0.37692] remaining[1:59:36]
01/08/2021 05:42:31 Task [ 2] updates[136500] train loss[0.37651] remaining[1:57:42]
01/08/2021 05:43:55 Task [ 0] updates[137000] train loss[0.37609] remaining[1:56:20]
01/08/2021 05:45:21 Task [ 2] updates[137500] train loss[0.37564] remaining[1:54:59]
01/08/2021 05:46:47 Task [ 0] updates[138000] train loss[0.37521] remaining[1:53:40]
01/08/2021 05:48:13 Task [ 2] updates[138500] train loss[0.37478] remaining[1:52:21]
01/08/2021 05:49:37 Task [ 0] updates[139000] train loss[0.37437] remaining[1:50:58]
01/08/2021 05:51:03 Task [ 0] updates[139500] train loss[0.37392] remaining[1:49:37]
01/08/2021 05:52:27 Task [ 2] updates[140000] train loss[0.37348] remaining[1:48:14]
01/08/2021 05:53:51 Task [ 0] updates[140500] train loss[0.37306] remaining[1:46:50]
01/08/2021 05:55:17 Task [ 2] updates[141000] train loss[0.37261] remaining[1:45:28]
01/08/2021 05:56:42 Task [ 2] updates[141500] train loss[0.37217] remaining[1:44:07]
01/08/2021 05:58:08 Task [ 0] updates[142000] train loss[0.37170] remaining[1:42:45]
01/08/2021 05:59:32 Task [ 0] updates[142500] train loss[0.37123] remaining[1:41:21]
01/08/2021 06:00:57 Task [ 3] updates[143000] train loss[0.37079] remaining[1:39:59]
01/08/2021 06:02:20 Task [ 0] updates[143500] train loss[0.37032] remaining[1:38:32]
01/08/2021 06:03:40 Task [ 0] updates[144000] train loss[0.36984] remaining[1:37:03]
01/08/2021 06:05:06 Task [ 2] updates[144500] train loss[0.36941] remaining[1:35:42]
01/08/2021 06:06:31 Task [ 0] updates[145000] train loss[0.36899] remaining[1:34:19]
01/08/2021 06:07:56 Task [ 2] updates[145500] train loss[0.36849] remaining[1:32:55]
01/08/2021 06:09:20 Task [ 3] updates[146000] train loss[0.36810] remaining[1:31:31]
01/08/2021 06:10:45 Task [ 2] updates[146500] train loss[0.36763] remaining[1:30:09]
01/08/2021 06:12:08 Task [ 0] updates[147000] train loss[0.36718] remaining[1:28:43]
01/08/2021 06:13:33 Task [ 0] updates[147500] train loss[0.36672] remaining[1:27:20]
01/08/2021 06:14:58 Task [ 6] updates[148000] train loss[0.36629] remaining[1:25:56]
01/08/2021 06:16:23 Task [ 0] updates[148500] train loss[0.36585] remaining[1:24:33]
01/08/2021 06:17:46 Task [ 3] updates[149000] train loss[0.36537] remaining[1:23:08]
01/08/2021 06:19:11 Task [ 3] updates[149500] train loss[0.36489] remaining[1:21:45]
01/08/2021 06:20:37 Task [ 3] updates[150000] train loss[0.36449] remaining[1:20:22]
01/08/2021 06:22:01 Task [ 0] updates[150500] train loss[0.36400] remaining[1:18:58]
01/08/2021 06:23:27 Task [ 2] updates[151000] train loss[0.36353] remaining[1:17:36]
01/08/2021 06:24:53 Task [ 2] updates[151500] train loss[0.36311] remaining[1:16:13]
01/08/2021 06:26:17 Task [ 5] updates[152000] train loss[0.36272] remaining[1:14:48]
01/08/2021 06:27:42 Task [ 2] updates[152500] train loss[0.36227] remaining[1:13:25]
01/08/2021 06:29:08 Task [ 0] updates[153000] train loss[0.36185] remaining[1:12:02]
01/08/2021 06:30:32 Task [ 2] updates[153500] train loss[0.36142] remaining[1:10:38]
01/08/2021 06:31:58 Task [ 0] updates[154000] train loss[0.36100] remaining[1:09:15]
01/08/2021 06:33:23 Task [ 0] updates[154500] train loss[0.36060] remaining[1:07:51]
01/08/2021 06:34:47 Task [ 4] updates[155000] train loss[0.36018] remaining[1:06:27]
01/08/2021 06:36:11 Task [ 0] updates[155500] train loss[0.35977] remaining[1:05:02]
01/08/2021 06:37:36 Task [ 2] updates[156000] train loss[0.35936] remaining[1:03:38]
01/08/2021 06:39:00 Task [ 2] updates[156500] train loss[0.35897] remaining[1:02:14]
01/08/2021 06:40:25 Task [ 0] updates[157000] train loss[0.35853] remaining[1:00:50]
01/08/2021 06:41:52 Task [ 0] updates[157500] train loss[0.35811] remaining[0:59:27]
01/08/2021 06:43:17 Task [ 0] updates[158000] train loss[0.35770] remaining[0:58:03]
01/08/2021 06:44:42 Task [ 3] updates[158500] train loss[0.35733] remaining[0:56:39]
01/08/2021 06:46:08 Task [ 0] updates[159000] train loss[0.35695] remaining[0:55:16]
01/08/2021 06:47:35 Task [ 3] updates[159500] train loss[0.35647] remaining[0:53:53]
01/08/2021 06:49:00 Task [ 0] updates[160000] train loss[0.35608] remaining[0:52:29]
01/08/2021 06:50:24 Task [ 0] updates[160500] train loss[0.35570] remaining[0:51:04]
01/08/2021 06:51:49 Task [ 3] updates[161000] train loss[0.35530] remaining[0:49:40]
01/08/2021 06:53:13 Task [ 2] updates[161500] train loss[0.35490] remaining[0:48:15]
01/08/2021 06:54:38 Task [ 2] updates[162000] train loss[0.35447] remaining[0:46:51]
01/08/2021 06:55:58 Task [ 2] updates[162500] train loss[0.35408] remaining[0:45:25]
01/08/2021 06:57:24 Task [ 2] updates[163000] train loss[0.35369] remaining[0:44:01]
01/08/2021 06:58:48 Task [ 0] updates[163500] train loss[0.35331] remaining[0:42:37]
01/08/2021 07:00:11 Task [ 0] updates[164000] train loss[0.35294] remaining[0:41:12]
01/08/2021 07:01:37 Task [ 2] updates[164500] train loss[0.35263] remaining[0:39:48]
01/08/2021 07:03:01 Task [ 0] updates[165000] train loss[0.35218] remaining[0:38:23]
01/08/2021 07:04:25 Task [ 2] updates[165500] train loss[0.35179] remaining[0:36:59]
01/08/2021 07:05:51 Task [ 0] updates[166000] train loss[0.35142] remaining[0:35:35]
01/08/2021 07:07:15 Task [ 0] updates[166500] train loss[0.35110] remaining[0:34:11]
01/08/2021 07:08:41 Task [ 0] updates[167000] train loss[0.35071] remaining[0:32:47]
01/08/2021 07:10:08 Task [ 0] updates[167500] train loss[0.35033] remaining[0:31:23]
01/08/2021 07:11:33 Task [ 2] updates[168000] train loss[0.34997] remaining[0:29:59]
01/08/2021 07:12:59 Task [ 5] updates[168500] train loss[0.34956] remaining[0:28:34]
01/08/2021 07:14:24 Task [ 0] updates[169000] train loss[0.34919] remaining[0:27:10]
01/08/2021 07:15:50 Task [ 0] updates[169500] train loss[0.34881] remaining[0:25:46]
01/08/2021 07:17:14 Task [ 2] updates[170000] train loss[0.34844] remaining[0:24:21]
01/08/2021 07:18:39 Task [ 2] updates[170500] train loss[0.34809] remaining[0:22:57]
01/08/2021 07:20:05 Task [ 0] updates[171000] train loss[0.34769] remaining[0:21:33]
01/08/2021 07:21:30 Task [ 3] updates[171500] train loss[0.34728] remaining[0:20:08]
01/08/2021 07:22:54 Task [ 3] updates[172000] train loss[0.34694] remaining[0:18:44]
01/08/2021 07:24:19 Task [ 2] updates[172500] train loss[0.34664] remaining[0:17:19]
01/08/2021 07:25:43 Task [ 2] updates[173000] train loss[0.34631] remaining[0:15:55]
01/08/2021 07:27:08 Task [ 2] updates[173500] train loss[0.34597] remaining[0:14:30]
01/08/2021 07:28:33 Task [ 0] updates[174000] train loss[0.34562] remaining[0:13:06]
01/08/2021 07:29:58 Task [ 2] updates[174500] train loss[0.34530] remaining[0:11:42]
01/08/2021 07:31:23 Task [ 0] updates[175000] train loss[0.34495] remaining[0:10:17]
01/08/2021 07:32:48 Task [ 2] updates[175500] train loss[0.34457] remaining[0:08:53]
01/08/2021 07:34:15 Task [ 0] updates[176000] train loss[0.34423] remaining[0:07:28]
01/08/2021 07:35:42 Task [ 0] updates[176500] train loss[0.34386] remaining[0:06:04]
01/08/2021 07:37:06 Task [ 5] updates[177000] train loss[0.34351] remaining[0:04:39]
01/08/2021 07:38:29 Task [ 0] updates[177500] train loss[0.34314] remaining[0:03:15]
01/08/2021 07:39:53 Task [ 5] updates[178000] train loss[0.34283] remaining[0:01:50]
01/08/2021 07:41:17 Task [ 2] updates[178500] train loss[0.34250] remaining[0:00:26]
01/08/2021 07:42:06 Task mnli_matched -- epoch 2 -- Dev ACC: 84.167
01/08/2021 07:42:29 [new test scores saved.]
01/08/2021 07:42:53 Task mnli_mismatched -- epoch 2 -- Dev ACC: 84.194
01/08/2021 07:43:17 [new test scores saved.]
01/08/2021 07:43:18 Task rte -- epoch 2 -- Dev ACC: 75.812
01/08/2021 07:43:27 [new test scores saved.]
01/08/2021 07:44:50 Task qqp -- epoch 2 -- Dev ACC: 90.398
01/08/2021 07:44:50 Task qqp -- epoch 2 -- Dev F1: 87.169
01/08/2021 07:58:24 [new test scores saved.]
01/08/2021 07:58:39 Task qnli -- epoch 2 -- Dev ACC: 87.718
01/08/2021 07:58:56 [new test scores saved.]
01/08/2021 07:58:57 Task mrpc -- epoch 2 -- Dev ACC: 80.882
01/08/2021 07:58:57 Task mrpc -- epoch 2 -- Dev F1: 86.735
01/08/2021 07:59:02 [new test scores saved.]
01/08/2021 07:59:03 Task sst -- epoch 2 -- Dev ACC: 93.119
01/08/2021 07:59:06 [new test scores saved.]
01/08/2021 07:59:08 Task cola -- epoch 2 -- Dev ACC: 79.866
01/08/2021 07:59:08 Task cola -- epoch 2 -- Dev MCC: 49.912
01/08/2021 07:59:10 [new test scores saved.]
01/08/2021 07:59:13 Task stsb -- epoch 2 -- Dev Pearson: 86.742
01/08/2021 07:59:13 Task stsb -- epoch 2 -- Dev Spearman: 86.899
01/08/2021 07:59:15 [new test scores saved.]
01/08/2021 07:59:20 At epoch 3
01/08/2021 08:00:19 Task [ 2] updates[179000] train loss[0.34216] remaining[2:46:15]
01/08/2021 08:01:44 Task [ 2] updates[179500] train loss[0.34181] remaining[2:45:55]
01/08/2021 08:03:10 Task [ 0] updates[180000] train loss[0.34146] remaining[2:45:17]
01/08/2021 08:04:27 Task [ 2] updates[180500] train loss[0.34118] remaining[2:39:54]
01/08/2021 08:05:50 Task [ 0] updates[181000] train loss[0.34084] remaining[2:38:30]
01/08/2021 08:07:18 Task [ 0] updates[181500] train loss[0.34050] remaining[2:38:31]
01/08/2021 08:08:44 Task [ 0] updates[182000] train loss[0.34015] remaining[2:37:54]
01/08/2021 08:10:10 Task [ 0] updates[182500] train loss[0.33985] remaining[2:36:49]
01/08/2021 08:11:34 Task [ 3] updates[183000] train loss[0.33955] remaining[2:35:24]
01/08/2021 08:12:57 Task [ 0] updates[183500] train loss[0.33925] remaining[2:33:45]
01/08/2021 08:14:21 Task [ 5] updates[184000] train loss[0.33895] remaining[2:32:15]
01/08/2021 08:15:48 Task [ 0] updates[184500] train loss[0.33868] remaining[2:31:09]
01/08/2021 08:17:12 Task [ 5] updates[185000] train loss[0.33838] remaining[2:29:48]
01/08/2021 08:18:39 Task [ 2] updates[185500] train loss[0.33808] remaining[2:28:40]
01/08/2021 08:20:04 Task [ 0] updates[186000] train loss[0.33777] remaining[2:27:22]
01/08/2021 08:21:32 Task [ 5] updates[186500] train loss[0.33747] remaining[2:26:15]
01/08/2021 08:22:57 Task [ 2] updates[187000] train loss[0.33715] remaining[2:24:51]
01/08/2021 08:24:25 Task [ 2] updates[187500] train loss[0.33683] remaining[2:23:44]
01/08/2021 08:25:51 Task [ 2] updates[188000] train loss[0.33653] remaining[2:22:26]
01/08/2021 08:27:18 Task [ 2] updates[188500] train loss[0.33621] remaining[2:21:10]
01/08/2021 08:28:41 Task [ 2] updates[189000] train loss[0.33587] remaining[2:19:34]
01/08/2021 08:30:09 Task [ 0] updates[189500] train loss[0.33558] remaining[2:18:20]
01/08/2021 08:31:36 Task [ 0] updates[190000] train loss[0.33529] remaining[2:17:05]
01/08/2021 08:33:01 Task [ 2] updates[190500] train loss[0.33496] remaining[2:15:39]
01/08/2021 08:34:29 Task [ 5] updates[191000] train loss[0.33463] remaining[2:14:24]
01/08/2021 08:36:06 Task [ 0] updates[191500] train loss[0.33429] remaining[2:13:40]
01/08/2021 08:37:41 Task [ 2] updates[192000] train loss[0.33395] remaining[2:12:44]
01/08/2021 08:39:07 Task [ 0] updates[192500] train loss[0.33363] remaining[2:11:19]
01/08/2021 08:40:34 Task [ 0] updates[193000] train loss[0.33329] remaining[2:09:55]
01/08/2021 08:41:51 Task [ 0] updates[193500] train loss[0.33305] remaining[2:08:00]
01/08/2021 08:43:07 Task [ 2] updates[194000] train loss[0.33274] remaining[2:06:07]
01/08/2021 08:44:28 Task [ 4] updates[194500] train loss[0.33242] remaining[2:04:27]
01/08/2021 08:45:50 Task [ 2] updates[195000] train loss[0.33209] remaining[2:02:54]
01/08/2021 08:47:26 Task [ 0] updates[195500] train loss[0.33178] remaining[2:01:54]
01/08/2021 08:48:51 Task [ 0] updates[196000] train loss[0.33144] remaining[2:00:28]
01/08/2021 08:50:12 Task [ 0] updates[196500] train loss[0.33114] remaining[1:58:52]
01/08/2021 08:51:33 Task [ 0] updates[197000] train loss[0.33085] remaining[1:57:16]
01/08/2021 08:52:54 Task [ 0] updates[197500] train loss[0.33053] remaining[1:55:41]
01/08/2021 08:54:22 Task [ 3] updates[198000] train loss[0.33022] remaining[1:54:21]
01/08/2021 08:55:46 Task [ 2] updates[198500] train loss[0.32991] remaining[1:52:54]
01/08/2021 08:57:10 Task [ 0] updates[199000] train loss[0.32959] remaining[1:51:25]
01/08/2021 08:58:30 Task [ 5] updates[199500] train loss[0.32927] remaining[1:49:50]
01/08/2021 08:59:51 Task [ 0] updates[200000] train loss[0.32897] remaining[1:48:19]
01/08/2021 09:01:15 Task [ 2] updates[200500] train loss[0.32868] remaining[1:46:51]
01/08/2021 09:02:38 Task [ 3] updates[201000] train loss[0.32834] remaining[1:45:22]
01/08/2021 09:04:02 Task [ 2] updates[201500] train loss[0.32802] remaining[1:43:56]
01/08/2021 09:05:24 Task [ 3] updates[202000] train loss[0.32767] remaining[1:42:27]
01/08/2021 09:06:49 Task [ 2] updates[202500] train loss[0.32736] remaining[1:41:01]
01/08/2021 09:08:12 Task [ 0] updates[203000] train loss[0.32704] remaining[1:39:34]
01/08/2021 09:09:36 Task [ 0] updates[203500] train loss[0.32671] remaining[1:38:08]
01/08/2021 09:11:00 Task [ 0] updates[204000] train loss[0.32641] remaining[1:36:42]
01/08/2021 09:12:23 Task [ 0] updates[204500] train loss[0.32609] remaining[1:35:16]
01/08/2021 09:13:48 Task [ 0] updates[205000] train loss[0.32579] remaining[1:33:51]
01/08/2021 09:15:12 Task [ 0] updates[205500] train loss[0.32548] remaining[1:32:24]
01/08/2021 09:16:37 Task [ 2] updates[206000] train loss[0.32516] remaining[1:31:01]
01/08/2021 09:18:00 Task [ 5] updates[206500] train loss[0.32484] remaining[1:29:34]
01/08/2021 09:19:23 Task [ 3] updates[207000] train loss[0.32454] remaining[1:28:07]
01/08/2021 09:20:48 Task [ 3] updates[207500] train loss[0.32422] remaining[1:26:42]
01/08/2021 09:22:11 Task [ 0] updates[208000] train loss[0.32392] remaining[1:25:16]
01/08/2021 09:23:35 Task [ 0] updates[208500] train loss[0.32357] remaining[1:23:51]
01/08/2021 09:24:58 Task [ 5] updates[209000] train loss[0.32324] remaining[1:22:24]
01/08/2021 09:26:21 Task [ 2] updates[209500] train loss[0.32294] remaining[1:20:58]
01/08/2021 09:27:43 Task [ 3] updates[210000] train loss[0.32262] remaining[1:19:31]
01/08/2021 09:29:08 Task [ 0] updates[210500] train loss[0.32226] remaining[1:18:07]
01/08/2021 09:30:31 Task [ 5] updates[211000] train loss[0.32201] remaining[1:16:41]
01/08/2021 09:31:55 Task [ 5] updates[211500] train loss[0.32174] remaining[1:15:16]
01/08/2021 09:33:20 Task [ 3] updates[212000] train loss[0.32143] remaining[1:13:52]
01/08/2021 09:34:44 Task [ 0] updates[212500] train loss[0.32115] remaining[1:12:26]
01/08/2021 09:36:10 Task [ 0] updates[213000] train loss[0.32082] remaining[1:11:03]
01/08/2021 09:37:34 Task [ 2] updates[213500] train loss[0.32053] remaining[1:09:38]
01/08/2021 09:38:57 Task [ 2] updates[214000] train loss[0.32024] remaining[1:08:12]
01/08/2021 09:40:20 Task [ 0] updates[214500] train loss[0.31994] remaining[1:06:47]
01/08/2021 09:41:44 Task [ 2] updates[215000] train loss[0.31963] remaining[1:05:22]
01/08/2021 09:43:07 Task [ 2] updates[215500] train loss[0.31933] remaining[1:03:57]
01/08/2021 09:44:32 Task [ 2] updates[216000] train loss[0.31904] remaining[1:02:32]
01/08/2021 09:45:54 Task [ 2] updates[216500] train loss[0.31872] remaining[1:01:07]
01/08/2021 09:47:16 Task [ 2] updates[217000] train loss[0.31843] remaining[0:59:41]
01/08/2021 09:48:40 Task [ 2] updates[217500] train loss[0.31814] remaining[0:58:16]
01/08/2021 09:50:03 Task [ 2] updates[218000] train loss[0.31784] remaining[0:56:51]
01/08/2021 09:51:20 Task [ 0] updates[218500] train loss[0.31754] remaining[0:55:23]
01/08/2021 09:52:30 Task [ 0] updates[219000] train loss[0.31722] remaining[0:53:52]
01/08/2021 09:53:50 Task [ 2] updates[219500] train loss[0.31692] remaining[0:52:26]
01/08/2021 09:55:15 Task [ 5] updates[220000] train loss[0.31663] remaining[0:51:02]
01/08/2021 09:56:39 Task [ 2] updates[220500] train loss[0.31636] remaining[0:49:38]
01/08/2021 09:58:01 Task [ 0] updates[221000] train loss[0.31606] remaining[0:48:13]
01/08/2021 09:59:24 Task [ 5] updates[221500] train loss[0.31575] remaining[0:46:48]
01/08/2021 10:00:49 Task [ 0] updates[222000] train loss[0.31549] remaining[0:45:24]
01/08/2021 10:02:13 Task [ 2] updates[222500] train loss[0.31521] remaining[0:44:00]
01/08/2021 10:03:37 Task [ 5] updates[223000] train loss[0.31492] remaining[0:42:36]
01/08/2021 10:05:01 Task [ 2] updates[223500] train loss[0.31465] remaining[0:41:12]
01/08/2021 10:06:24 Task [ 0] updates[224000] train loss[0.31441] remaining[0:39:48]
01/08/2021 10:07:46 Task [ 2] updates[224500] train loss[0.31414] remaining[0:38:23]
01/08/2021 10:09:08 Task [ 2] updates[225000] train loss[0.31385] remaining[0:36:59]
01/08/2021 10:10:19 Task [ 2] updates[225500] train loss[0.31356] remaining[0:35:31]
01/08/2021 10:11:37 Task [ 2] updates[226000] train loss[0.31328] remaining[0:34:06]
01/08/2021 10:12:58 Task [ 0] updates[226500] train loss[0.31300] remaining[0:32:41]
01/08/2021 10:14:23 Task [ 0] updates[227000] train loss[0.31274] remaining[0:31:18]
01/08/2021 10:15:47 Task [ 2] updates[227500] train loss[0.31245] remaining[0:29:54]
01/08/2021 10:17:10 Task [ 0] updates[228000] train loss[0.31217] remaining[0:28:30]
01/08/2021 10:18:33 Task [ 0] updates[228500] train loss[0.31189] remaining[0:27:06]
01/08/2021 10:19:56 Task [ 0] updates[229000] train loss[0.31159] remaining[0:25:42]
01/08/2021 10:21:16 Task [ 0] updates[229500] train loss[0.31134] remaining[0:24:17]
01/08/2021 10:22:26 Task [ 2] updates[230000] train loss[0.31108] remaining[0:22:52]
01/08/2021 10:23:36 Task [ 2] updates[230500] train loss[0.31077] remaining[0:21:26]
01/08/2021 10:24:50 Task [ 2] updates[231000] train loss[0.31048] remaining[0:20:01]
01/08/2021 10:26:15 Task [ 2] updates[231500] train loss[0.31023] remaining[0:18:38]
01/08/2021 10:27:40 Task [ 3] updates[232000] train loss[0.30998] remaining[0:17:15]
01/08/2021 10:28:59 Task [ 2] updates[232500] train loss[0.30972] remaining[0:15:51]
01/08/2021 10:30:21 Task [ 0] updates[233000] train loss[0.30947] remaining[0:14:27]
01/08/2021 10:31:46 Task [ 3] updates[233500] train loss[0.30922] remaining[0:13:04]
01/08/2021 10:33:07 Task [ 0] updates[234000] train loss[0.30898] remaining[0:11:41]
01/08/2021 10:34:31 Task [ 2] updates[234500] train loss[0.30871] remaining[0:10:17]
01/08/2021 10:35:55 Task [ 0] updates[235000] train loss[0.30843] remaining[0:08:54]
01/08/2021 10:37:20 Task [ 0] updates[235500] train loss[0.30817] remaining[0:07:31]
01/08/2021 10:38:41 Task [ 2] updates[236000] train loss[0.30790] remaining[0:06:07]
01/08/2021 10:40:05 Task [ 0] updates[236500] train loss[0.30763] remaining[0:04:44]
01/08/2021 10:41:29 Task [ 2] updates[237000] train loss[0.30733] remaining[0:03:21]
01/08/2021 10:42:54 Task [ 0] updates[237500] train loss[0.30710] remaining[0:01:57]
01/08/2021 10:44:16 Task [ 0] updates[238000] train loss[0.30683] remaining[0:00:34]
01/08/2021 10:45:13 Task mnli_matched -- epoch 3 -- Dev ACC: 84.249
01/08/2021 10:45:36 [new test scores saved.]
01/08/2021 10:46:00 Task mnli_mismatched -- epoch 3 -- Dev ACC: 84.317
01/08/2021 10:46:23 [new test scores saved.]
01/08/2021 10:46:25 Task rte -- epoch 3 -- Dev ACC: 76.534
01/08/2021 10:46:33 [new test scores saved.]
01/08/2021 10:47:56 Task qqp -- epoch 3 -- Dev ACC: 90.772
01/08/2021 10:47:56 Task qqp -- epoch 3 -- Dev F1: 87.661
01/08/2021 11:01:24 [new test scores saved.]
01/08/2021 11:01:39 Task qnli -- epoch 3 -- Dev ACC: 87.927
01/08/2021 11:01:56 [new test scores saved.]
01/08/2021 11:01:57 Task mrpc -- epoch 3 -- Dev ACC: 81.127
01/08/2021 11:01:57 Task mrpc -- epoch 3 -- Dev F1: 86.792
01/08/2021 11:02:02 [new test scores saved.]
01/08/2021 11:02:03 Task sst -- epoch 3 -- Dev ACC: 92.775
01/08/2021 11:02:06 [new test scores saved.]
01/08/2021 11:02:08 Task cola -- epoch 3 -- Dev ACC: 79.674
01/08/2021 11:02:08 Task cola -- epoch 3 -- Dev MCC: 49.549
01/08/2021 11:02:10 [new test scores saved.]
01/08/2021 11:02:13 Task stsb -- epoch 3 -- Dev Pearson: 86.619
01/08/2021 11:02:13 Task stsb -- epoch 3 -- Dev Spearman: 86.718
01/08/2021 11:02:16 [new test scores saved.]
01/08/2021 11:02:20 At epoch 4
01/08/2021 11:03:14 Task [ 0] updates[238500] train loss[0.30657] remaining[3:02:03]
01/08/2021 11:04:41 Task [ 3] updates[239000] train loss[0.30631] remaining[2:53:48]
01/08/2021 11:06:08 Task [ 0] updates[239500] train loss[0.30606] remaining[2:51:15]
01/08/2021 11:07:32 Task [ 2] updates[240000] train loss[0.30584] remaining[2:47:25]
01/08/2021 11:09:00 Task [ 2] updates[240500] train loss[0.30559] remaining[2:46:19]
01/08/2021 11:10:23 Task [ 0] updates[241000] train loss[0.30534] remaining[2:43:38]
01/08/2021 11:11:46 Task [ 2] updates[241500] train loss[0.30505] remaining[2:41:12]
01/08/2021 11:13:10 Task [ 3] updates[242000] train loss[0.30480] remaining[2:39:15]
01/08/2021 11:14:35 Task [ 2] updates[242500] train loss[0.30459] remaining[2:37:43]
01/08/2021 11:15:59 Task [ 0] updates[243000] train loss[0.30438] remaining[2:35:58]
01/08/2021 11:17:24 Task [ 2] updates[243500] train loss[0.30413] remaining[2:34:24]
01/08/2021 11:18:49 Task [ 2] updates[244000] train loss[0.30392] remaining[2:32:57]
01/08/2021 11:20:13 Task [ 0] updates[244500] train loss[0.30369] remaining[2:31:21]
01/08/2021 11:21:36 Task [ 0] updates[245000] train loss[0.30344] remaining[2:29:38]
01/08/2021 11:23:00 Task [ 2] updates[245500] train loss[0.30321] remaining[2:28:01]
01/08/2021 11:24:25 Task [ 0] updates[246000] train loss[0.30299] remaining[2:26:36]
01/08/2021 11:25:48 Task [ 2] updates[246500] train loss[0.30276] remaining[2:25:04]
01/08/2021 11:27:13 Task [ 5] updates[247000] train loss[0.30254] remaining[2:23:36]
01/08/2021 11:28:37 Task [ 2] updates[247500] train loss[0.30232] remaining[2:22:07]
01/08/2021 11:30:00 Task [ 2] updates[248000] train loss[0.30207] remaining[2:20:33]
01/08/2021 11:31:24 Task [ 0] updates[248500] train loss[0.30183] remaining[2:19:03]
01/08/2021 11:32:48 Task [ 0] updates[249000] train loss[0.30158] remaining[2:17:35]
01/08/2021 11:34:12 Task [ 2] updates[249500] train loss[0.30134] remaining[2:16:10]
01/08/2021 11:35:40 Task [ 2] updates[250000] train loss[0.30110] remaining[2:14:58]
01/08/2021 11:37:05 Task [ 2] updates[250500] train loss[0.30083] remaining[2:13:34]
01/08/2021 11:38:30 Task [ 2] updates[251000] train loss[0.30060] remaining[2:12:11]
01/08/2021 11:39:55 Task [ 2] updates[251500] train loss[0.30033] remaining[2:10:48]
01/08/2021 11:41:23 Task [ 3] updates[252000] train loss[0.30006] remaining[2:09:30]
01/08/2021 11:42:47 Task [ 0] updates[252500] train loss[0.29982] remaining[2:08:03]
01/08/2021 11:44:11 Task [ 2] updates[253000] train loss[0.29960] remaining[2:06:38]
01/08/2021 11:45:38 Task [ 2] updates[253500] train loss[0.29939] remaining[2:05:18]
01/08/2021 11:47:03 Task [ 0] updates[254000] train loss[0.29916] remaining[2:03:53]
01/08/2021 11:48:29 Task [ 2] updates[254500] train loss[0.29893] remaining[2:02:30]
01/08/2021 11:49:55 Task [ 2] updates[255000] train loss[0.29871] remaining[2:01:07]
01/08/2021 11:51:22 Task [ 3] updates[255500] train loss[0.29846] remaining[1:59:47]
01/08/2021 11:52:47 Task [ 0] updates[256000] train loss[0.29823] remaining[1:58:23]
01/08/2021 11:54:12 Task [ 0] updates[256500] train loss[0.29802] remaining[1:56:58]
01/08/2021 11:55:37 Task [ 0] updates[257000] train loss[0.29777] remaining[1:55:33]
01/08/2021 11:57:01 Task [ 2] updates[257500] train loss[0.29752] remaining[1:54:06]
01/08/2021 11:58:25 Task [ 2] updates[258000] train loss[0.29730] remaining[1:52:38]
01/08/2021 11:59:49 Task [ 2] updates[258500] train loss[0.29707] remaining[1:51:12]
01/08/2021 12:01:14 Task [ 0] updates[259000] train loss[0.29682] remaining[1:49:46]
01/08/2021 12:02:38 Task [ 0] updates[259500] train loss[0.29657] remaining[1:48:20]
01/08/2021 12:04:03 Task [ 0] updates[260000] train loss[0.29635] remaining[1:46:54]
01/08/2021 12:05:31 Task [ 0] updates[260500] train loss[0.29612] remaining[1:45:34]
01/08/2021 12:06:57 Task [ 3] updates[261000] train loss[0.29586] remaining[1:44:11]
01/08/2021 12:08:24 Task [ 0] updates[261500] train loss[0.29561] remaining[1:42:49]
01/08/2021 12:09:50 Task [ 0] updates[262000] train loss[0.29540] remaining[1:41:26]
01/08/2021 12:11:16 Task [ 0] updates[262500] train loss[0.29514] remaining[1:40:01]
01/08/2021 12:12:39 Task [ 0] updates[263000] train loss[0.29488] remaining[1:38:35]
01/08/2021 12:14:05 Task [ 3] updates[263500] train loss[0.29464] remaining[1:37:11]
01/08/2021 12:15:31 Task [ 3] updates[264000] train loss[0.29441] remaining[1:35:47]
01/08/2021 12:16:58 Task [ 2] updates[264500] train loss[0.29417] remaining[1:34:23]
01/08/2021 12:18:21 Task [ 2] updates[265000] train loss[0.29392] remaining[1:32:56]
01/08/2021 12:19:47 Task [ 3] updates[265500] train loss[0.29368] remaining[1:31:32]
01/08/2021 12:21:14 Task [ 2] updates[266000] train loss[0.29343] remaining[1:30:09]
01/08/2021 12:22:38 Task [ 0] updates[266500] train loss[0.29322] remaining[1:28:42]
01/08/2021 12:24:03 Task [ 2] updates[267000] train loss[0.29297] remaining[1:27:17]
01/08/2021 12:25:32 Task [ 0] updates[267500] train loss[0.29271] remaining[1:25:56]
01/08/2021 12:26:57 Task [ 2] updates[268000] train loss[0.29246] remaining[1:24:31]
01/08/2021 12:28:23 Task [ 0] updates[268500] train loss[0.29220] remaining[1:23:06]
01/08/2021 12:29:50 Task [ 3] updates[269000] train loss[0.29194] remaining[1:21:42]
01/08/2021 12:31:18 Task [ 2] updates[269500] train loss[0.29171] remaining[1:20:20]
01/08/2021 12:32:45 Task [ 3] updates[270000] train loss[0.29144] remaining[1:18:55]
01/08/2021 12:34:07 Task [ 5] updates[270500] train loss[0.29119] remaining[1:17:28]
01/08/2021 12:35:33 Task [ 5] updates[271000] train loss[0.29097] remaining[1:16:03]
01/08/2021 12:36:59 Task [ 3] updates[271500] train loss[0.29074] remaining[1:14:38]
01/08/2021 12:38:24 Task [ 2] updates[272000] train loss[0.29051] remaining[1:13:13]
01/08/2021 12:39:49 Task [ 0] updates[272500] train loss[0.29028] remaining[1:11:47]
01/08/2021 12:41:13 Task [ 3] updates[273000] train loss[0.29004] remaining[1:10:21]
01/08/2021 12:42:38 Task [ 0] updates[273500] train loss[0.28982] remaining[1:08:56]
01/08/2021 12:44:04 Task [ 0] updates[274000] train loss[0.28958] remaining[1:07:31]
01/08/2021 12:45:30 Task [ 3] updates[274500] train loss[0.28935] remaining[1:06:06]
01/08/2021 12:46:57 Task [ 2] updates[275000] train loss[0.28916] remaining[1:04:42]
01/08/2021 12:48:23 Task [ 0] updates[275500] train loss[0.28895] remaining[1:03:17]
01/08/2021 12:49:50 Task [ 2] updates[276000] train loss[0.28869] remaining[1:01:53]
01/08/2021 12:51:17 Task [ 5] updates[276500] train loss[0.28845] remaining[1:00:28]
01/08/2021 12:52:37 Task [ 2] updates[277000] train loss[0.28822] remaining[0:59:00]
01/08/2021 12:54:02 Task [ 0] updates[277500] train loss[0.28802] remaining[0:57:35]
01/08/2021 12:55:26 Task [ 0] updates[278000] train loss[0.28780] remaining[0:56:09]
01/08/2021 12:56:50 Task [ 2] updates[278500] train loss[0.28758] remaining[0:54:43]
01/08/2021 12:58:16 Task [ 0] updates[279000] train loss[0.28735] remaining[0:53:18]
01/08/2021 12:59:41 Task [ 2] updates[279500] train loss[0.28711] remaining[0:51:52]
01/08/2021 01:01:06 Task [ 2] updates[280000] train loss[0.28692] remaining[0:50:27]
01/08/2021 01:02:30 Task [ 0] updates[280500] train loss[0.28669] remaining[0:49:01]
01/08/2021 01:03:55 Task [ 0] updates[281000] train loss[0.28645] remaining[0:47:36]
01/08/2021 01:05:22 Task [ 5] updates[281500] train loss[0.28626] remaining[0:46:12]
01/08/2021 01:06:46 Task [ 4] updates[282000] train loss[0.28604] remaining[0:44:46]
01/08/2021 01:08:11 Task [ 0] updates[282500] train loss[0.28582] remaining[0:43:20]
01/08/2021 01:09:35 Task [ 5] updates[283000] train loss[0.28559] remaining[0:41:55]
01/08/2021 01:10:59 Task [ 0] updates[283500] train loss[0.28540] remaining[0:40:29]
01/08/2021 01:12:23 Task [ 0] updates[284000] train loss[0.28519] remaining[0:39:04]
01/08/2021 01:13:48 Task [ 3] updates[284500] train loss[0.28498] remaining[0:37:38]
01/08/2021 01:15:12 Task [ 0] updates[285000] train loss[0.28474] remaining[0:36:13]
01/08/2021 01:16:38 Task [ 3] updates[285500] train loss[0.28453] remaining[0:34:48]
01/08/2021 01:18:02 Task [ 0] updates[286000] train loss[0.28434] remaining[0:33:22]
01/08/2021 01:19:25 Task [ 2] updates[286500] train loss[0.28412] remaining[0:31:57]
01/08/2021 01:20:52 Task [ 2] updates[287000] train loss[0.28392] remaining[0:30:32]
01/08/2021 01:22:16 Task [ 0] updates[287500] train loss[0.28369] remaining[0:29:07]
01/08/2021 01:23:40 Task [ 3] updates[288000] train loss[0.28350] remaining[0:27:41]
01/08/2021 01:25:05 Task [ 0] updates[288500] train loss[0.28328] remaining[0:26:16]
01/08/2021 01:26:29 Task [ 2] updates[289000] train loss[0.28307] remaining[0:24:51]
01/08/2021 01:27:54 Task [ 2] updates[289500] train loss[0.28288] remaining[0:23:26]
01/08/2021 01:29:08 Task [ 2] updates[290000] train loss[0.28264] remaining[0:21:59]
01/08/2021 01:30:33 Task [ 0] updates[290500] train loss[0.28241] remaining[0:20:34]
01/08/2021 01:31:58 Task [ 3] updates[291000] train loss[0.28222] remaining[0:19:09]
01/08/2021 01:33:22 Task [ 0] updates[291500] train loss[0.28202] remaining[0:17:44]
01/08/2021 01:34:46 Task [ 3] updates[292000] train loss[0.28183] remaining[0:16:18]
01/08/2021 01:36:11 Task [ 2] updates[292500] train loss[0.28166] remaining[0:14:53]
01/08/2021 01:37:34 Task [ 3] updates[293000] train loss[0.28147] remaining[0:13:28]
01/08/2021 01:38:57 Task [ 3] updates[293500] train loss[0.28129] remaining[0:12:03]
01/08/2021 01:40:21 Task [ 0] updates[294000] train loss[0.28110] remaining[0:10:38]
01/08/2021 01:41:50 Task [ 2] updates[294500] train loss[0.28089] remaining[0:09:13]
01/08/2021 01:43:14 Task [ 0] updates[295000] train loss[0.28069] remaining[0:07:48]
01/08/2021 01:44:39 Task [ 0] updates[295500] train loss[0.28049] remaining[0:06:23]
01/08/2021 01:46:05 Task [ 3] updates[296000] train loss[0.28028] remaining[0:04:58]
01/08/2021 01:47:29 Task [ 2] updates[296500] train loss[0.28007] remaining[0:03:33]
01/08/2021 01:48:58 Task [ 0] updates[297000] train loss[0.27989] remaining[0:02:08]
01/08/2021 01:50:19 Task [ 2] updates[297500] train loss[0.27969] remaining[0:00:43]
01/08/2021 01:51:29 Task mnli_matched -- epoch 4 -- Dev ACC: 84.157
01/08/2021 01:51:52 [new test scores saved.]
01/08/2021 01:52:17 Task mnli_mismatched -- epoch 4 -- Dev ACC: 84.388
01/08/2021 01:52:41 [new test scores saved.]
01/08/2021 01:52:42 Task rte -- epoch 4 -- Dev ACC: 78.339
01/08/2021 01:52:51 [new test scores saved.]
01/08/2021 01:54:16 Task qqp -- epoch 4 -- Dev ACC: 90.816
01/08/2021 01:54:16 Task qqp -- epoch 4 -- Dev F1: 87.707
01/08/2021 02:08:12 [new test scores saved.]
01/08/2021 02:08:27 Task qnli -- epoch 4 -- Dev ACC: 87.736
01/08/2021 02:08:45 [new test scores saved.]
01/08/2021 02:08:46 Task mrpc -- epoch 4 -- Dev ACC: 81.127
01/08/2021 02:08:46 Task mrpc -- epoch 4 -- Dev F1: 86.275
01/08/2021 02:08:50 [new test scores saved.]
01/08/2021 02:08:52 Task sst -- epoch 4 -- Dev ACC: 91.972
01/08/2021 02:08:56 [new test scores saved.]
01/08/2021 02:08:58 Task cola -- epoch 4 -- Dev ACC: 81.592
01/08/2021 02:08:58 Task cola -- epoch 4 -- Dev MCC: 54.674
01/08/2021 02:09:00 [new test scores saved.]
01/08/2021 02:09:04 Task stsb -- epoch 4 -- Dev Pearson: 86.522
01/08/2021 02:09:04 Task stsb -- epoch 4 -- Dev Spearman: 86.647
01/08/2021 02:09:07 [new test scores saved.]
